{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "lab.ipynb",
      "provenance": []
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "WZfImSn8R0d0",
        "colab_type": "text"
      },
      "source": [
        "<b>Google Colab</b> <a href=\"https://colab.research.google.com/github/kirillzyusko/deeplearning/blob/master/7/lab.ipynb\">link</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml1ygy5_uBJS",
        "colab_type": "text"
      },
      "source": [
        "Authorize google + kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKErrc71uBQb",
        "colab_type": "code",
        "outputId": "9fae13ba-d051-4e42-9c94-218195481fba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "from googleapiclient.discovery import build\n",
        "import io, os\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "results = drive_service.files().list(\n",
        "        q=\"name = 'kaggle.json'\", fields=\"files(id)\").execute()\n",
        "kaggle_api_key = results.get('files', [])\n",
        "filename = \"/content/.kaggle/kaggle.json\"\n",
        "os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "request = drive_service.files().get_media(fileId=kaggle_api_key[0]['id'])\n",
        "fh = io.FileIO(filename, 'wb')\n",
        "downloader = MediaIoBaseDownload(fh, request)\n",
        "done = False\n",
        "while done is False:\n",
        "    status, done = downloader.next_chunk()\n",
        "    print(\"Download %d%%.\" % int(status.progress() * 100))\n",
        "os.chmod(filename, 600)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "Download 100%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "190Qk0KuuUSa",
        "colab_type": "text"
      },
      "source": [
        "Be sure, that we authorized and have an access to kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYY0Nxi_uUZO",
        "colab_type": "code",
        "outputId": "6325fa80-4b17-4189-feb7-c59661ccb3c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%ls /content/.kaggle/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;32mkaggle.json\u001b[0m*\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5g0sOvfQO1nc",
        "colab_type": "text"
      },
      "source": [
        "# **Part 1: Download dataset, extract**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6Xdl2_LPDxg",
        "colab_type": "text"
      },
      "source": [
        "Download dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cca54DmnPD5S",
        "colab_type": "code",
        "outputId": "55127814-6faa-4309-b0fa-fffdea1b2478",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download lakshmi25npathi/imdb-dataset-of-50k-movie-reviews -p /content/kaggle/imdb"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading imdb-dataset-of-50k-movie-reviews.zip to /content/kaggle/imdb\n",
            " 97% 25.0M/25.7M [00:00<00:00, 38.9MB/s]\n",
            "100% 25.7M/25.7M [00:00<00:00, 37.6MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2hNyXbPvSQa",
        "colab_type": "text"
      },
      "source": [
        "Extract .zip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99z2-nHFvT5B",
        "colab_type": "code",
        "outputId": "4d8c4011-754d-4187-8d34-00fc61f8721f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!unzip kaggle/imdb/imdb-dataset-of-50k-movie-reviews.zip -d data"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  kaggle/imdb/imdb-dataset-of-50k-movie-reviews.zip\n",
            "  inflating: data/IMDB Dataset.csv   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3LwHVDEwcLD",
        "colab_type": "text"
      },
      "source": [
        "Files:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeETnYp5wby8",
        "colab_type": "code",
        "outputId": "6607b7b6-23db-4d81-900c-89bb3087b1f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%ls data"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'IMDB Dataset.csv'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8UdGt-Pw8Mf",
        "colab_type": "text"
      },
      "source": [
        "Read data using pandas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "489LXKpvw8S0",
        "colab_type": "code",
        "outputId": "f8f056f0-9d93-49ea-9d54-a8bbfd6a563e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('data/IMDB Dataset.csv')\n",
        "print(df.shape)\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBnNRwRS1dRs",
        "colab_type": "text"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caAMPNsZv575",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import SimpleRNN\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import Bidirectional\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mgqRl7JwOY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dictionary_length = 10000\n",
        "input_length = 100\n",
        "\n",
        "tokenizer = Tokenizer(num_words=dictionary_length)\n",
        "tokenizer.fit_on_texts(df.review.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmPueIwywc3B",
        "colab_type": "code",
        "outputId": "fbda3d4d-ec58-42a6-8098-f704ff958941",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "post_seq = tokenizer.texts_to_sequences(df.review.values)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 124252 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLRPD1rdwgE5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "post_seq_padded = pad_sequences(post_seq, maxlen=input_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1iluafsxFXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "x_original = post_seq_padded\n",
        "x_original = np.array(x_original)\n",
        "\n",
        "y_original = df['sentiment'].replace({ 'positive': 1, 'negative': 0 }).values\n",
        "y_original = np.array(y_original)\n",
        "\n",
        "x, y = shuffle(x_original, y_original, random_state=23)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beAbDT-vxM6u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5, random_state=42)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6etXKKLfO2h5",
        "colab_type": "text"
      },
      "source": [
        "# **Part 2: RNN with LSTM**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtE3byXjz7lR",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmeTQ6tcxVpo",
        "colab_type": "code",
        "outputId": "8368e298-f5cb-4d5e-e0fc-7a788cae2d33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(dictionary_length, 8, input_length=input_length))\n",
        "model.add(Bidirectional(LSTM(16, return_sequences=False))) # dropout=0.2, recurrent_dropout=0.2\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_10 (Embedding)     (None, 100, 8)            80000     \n",
            "_________________________________________________________________\n",
            "bidirectional_18 (Bidirectio (None, 32)                3200      \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 83,233\n",
            "Trainable params: 83,233\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBPVAf9VxoBG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sznaUdIBxtwI",
        "colab_type": "code",
        "outputId": "94f72c01-7fd9-4489-e1f7-4396015cca07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "model.fit(x=x_train, y=y_train, batch_size=256, verbose=1, epochs=10, validation_data=(x_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.6516 - accuracy: 0.6165 - val_loss: 0.4897 - val_accuracy: 0.7408\n",
            "Epoch 2/10\n",
            "79/79 [==============================] - 1s 14ms/step - loss: 0.3705 - accuracy: 0.8431 - val_loss: 0.4038 - val_accuracy: 0.8268\n",
            "Epoch 3/10\n",
            "79/79 [==============================] - 1s 15ms/step - loss: 0.2742 - accuracy: 0.8924 - val_loss: 0.3578 - val_accuracy: 0.8528\n",
            "Epoch 4/10\n",
            "79/79 [==============================] - 1s 15ms/step - loss: 0.2252 - accuracy: 0.9172 - val_loss: 0.4646 - val_accuracy: 0.8116\n",
            "Epoch 5/10\n",
            "79/79 [==============================] - 1s 15ms/step - loss: 0.1945 - accuracy: 0.9288 - val_loss: 0.4152 - val_accuracy: 0.8450\n",
            "Epoch 6/10\n",
            "79/79 [==============================] - 1s 15ms/step - loss: 0.1591 - accuracy: 0.9445 - val_loss: 0.4120 - val_accuracy: 0.8424\n",
            "Epoch 7/10\n",
            "79/79 [==============================] - 1s 15ms/step - loss: 0.1351 - accuracy: 0.9560 - val_loss: 0.4886 - val_accuracy: 0.8356\n",
            "Epoch 8/10\n",
            "79/79 [==============================] - 1s 15ms/step - loss: 0.1186 - accuracy: 0.9608 - val_loss: 0.5074 - val_accuracy: 0.8394\n",
            "Epoch 9/10\n",
            "79/79 [==============================] - 1s 15ms/step - loss: 0.1015 - accuracy: 0.9682 - val_loss: 0.5249 - val_accuracy: 0.8326\n",
            "Epoch 10/10\n",
            "79/79 [==============================] - 1s 15ms/step - loss: 0.0912 - accuracy: 0.9732 - val_loss: 0.5607 - val_accuracy: 0.8320\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f47d0ec9c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVKqkwetxxHD",
        "colab_type": "code",
        "outputId": "78fe3416-72f5-425c-e1b5-5f8786719baf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 4s 6ms/step - loss: 0.5428 - accuracy: 0.8340\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.542818009853363, 0.8339599967002869]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIrvEkMaO2uP",
        "colab_type": "text"
      },
      "source": [
        "# **Part 3: Using GloVe**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlaKV6VOPFCI",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MpP3hLeAiT6",
        "colab_type": "code",
        "outputId": "cc12e055-3447-450b-bf3a-e0c666289349",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "!wget \"http://nlp.stanford.edu/data/glove.6B.zip\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-03 21:06:25--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-04-03 21:06:26--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-04-03 21:06:26--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.02MB/s    in 6m 39s  \n",
            "\n",
            "2020-04-03 21:13:06 (2.06 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gADgatQ0A0sv",
        "colab_type": "code",
        "outputId": "945fb51d-453b-4a42-8fea-f4e3fa0609f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!mkdir glove\n",
        "!unzip glove.6B.zip -d glove"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove/glove.6B.50d.txt  \n",
            "  inflating: glove/glove.6B.100d.txt  \n",
            "  inflating: glove/glove.6B.200d.txt  \n",
            "  inflating: glove/glove.6B.300d.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtWg-lOaCHPH",
        "colab_type": "code",
        "outputId": "66e6ab67-c8c2-43e9-95a4-28ecf9f1c520",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "glove_dir = 'glove'\n",
        "\n",
        "embeddings_index = {}\n",
        "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YheEVG1CCPIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_dim = 100\n",
        "\n",
        "embedding_matrix = np.zeros((dictionary_length, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if i < dictionary_length:\n",
        "        if embedding_vector is not None:\n",
        "            # Words not found in embedding index will be all-zeros.\n",
        "            embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXW2oZM9CjIw",
        "colab_type": "code",
        "outputId": "6220dca9-a488-4876-d53a-7a509b7b8998",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(dictionary_length, embedding_dim, input_length=input_length))\n",
        "model.add(Bidirectional(LSTM(16))) # dropout=0.2, recurrent_dropout=0.2\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.layers[0].set_weights([embedding_matrix])\n",
        "model.layers[0].trainable = False\n",
        "\n",
        "# try using different optimizers and different optimizer configs\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=10, verbose=1, validation_data=(x_val, y_val))\n",
        "score, acc = model.evaluate(x_test, y_test)\n",
        "\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_11 (Embedding)     (None, 100, 100)          1000000   \n",
            "_________________________________________________________________\n",
            "bidirectional_19 (Bidirectio (None, 32)                14976     \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 1,015,009\n",
            "Trainable params: 1,015,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 0.5689 - accuracy: 0.6964 - val_loss: 0.4867 - val_accuracy: 0.7644\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 7s 11ms/step - loss: 0.4412 - accuracy: 0.7943 - val_loss: 0.4050 - val_accuracy: 0.8112\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 7s 11ms/step - loss: 0.4041 - accuracy: 0.8141 - val_loss: 0.3886 - val_accuracy: 0.8222\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 7s 11ms/step - loss: 0.3761 - accuracy: 0.8281 - val_loss: 0.3772 - val_accuracy: 0.8258\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 7s 11ms/step - loss: 0.3539 - accuracy: 0.8420 - val_loss: 0.3653 - val_accuracy: 0.8308\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 7s 11ms/step - loss: 0.3361 - accuracy: 0.8504 - val_loss: 0.3625 - val_accuracy: 0.8326\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 7s 11ms/step - loss: 0.3239 - accuracy: 0.8547 - val_loss: 0.3516 - val_accuracy: 0.8390\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 7s 11ms/step - loss: 0.3098 - accuracy: 0.8657 - val_loss: 0.3470 - val_accuracy: 0.8392\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 7s 11ms/step - loss: 0.2958 - accuracy: 0.8712 - val_loss: 0.3685 - val_accuracy: 0.8350\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 7s 11ms/step - loss: 0.2831 - accuracy: 0.8773 - val_loss: 0.3467 - val_accuracy: 0.8438\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.3442 - accuracy: 0.8490\n",
            "Test accuracy: 0.8490399718284607\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1M7MEHJSO22X",
        "colab_type": "text"
      },
      "source": [
        "# **Part 4: New NN architecture**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50EL3cv5PFyH",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNZLyrdiPF4A",
        "colab_type": "code",
        "outputId": "86ac9fd0-dd74-4d45-957f-6f11547fb61a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(dictionary_length, embedding_dim, input_length=input_length))\n",
        "model.add(Bidirectional(LSTM(32, return_sequences=True))) # dropout=0.2, recurrent_dropout=0.2\n",
        "model.add(Bidirectional(LSTM(32, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(32)))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.layers[0].set_weights([embedding_matrix])\n",
        "model.layers[0].trainable = False\n",
        "\n",
        "# try using different optimizers and different optimizer configs\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=10, verbose=1, validation_data=(x_val, y_val))\n",
        "score, acc = model.evaluate(x_test, y_test)\n",
        "\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_12 (Embedding)     (None, 100, 100)          1000000   \n",
            "_________________________________________________________________\n",
            "bidirectional_20 (Bidirectio (None, 100, 64)           34048     \n",
            "_________________________________________________________________\n",
            "bidirectional_21 (Bidirectio (None, 100, 64)           24832     \n",
            "_________________________________________________________________\n",
            "bidirectional_22 (Bidirectio (None, 64)                24832     \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 1,096,193\n",
            "Trainable params: 1,096,193\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 0.5607 - accuracy: 0.7060 - val_loss: 0.4779 - val_accuracy: 0.7506\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.4290 - accuracy: 0.8002 - val_loss: 0.4393 - val_accuracy: 0.7866\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 0.3808 - accuracy: 0.8261 - val_loss: 0.3892 - val_accuracy: 0.8224\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 0.3450 - accuracy: 0.8483 - val_loss: 0.3645 - val_accuracy: 0.8354\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 0.3193 - accuracy: 0.8583 - val_loss: 0.3884 - val_accuracy: 0.8200\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 0.3001 - accuracy: 0.8698 - val_loss: 0.3517 - val_accuracy: 0.8432\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 0.2764 - accuracy: 0.8809 - val_loss: 0.3580 - val_accuracy: 0.8458\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 0.2521 - accuracy: 0.8916 - val_loss: 0.3554 - val_accuracy: 0.8500\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 0.2321 - accuracy: 0.9016 - val_loss: 0.4230 - val_accuracy: 0.8310\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 0.2073 - accuracy: 0.9181 - val_loss: 0.4219 - val_accuracy: 0.8354\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.4177 - accuracy: 0.8357\n",
            "Test accuracy: 0.8356800079345703\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMVJI_wiS3XE",
        "colab_type": "text"
      },
      "source": [
        "# **Part 5: DeepMoji**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EB7OXRl-TBx5",
        "colab_type": "text"
      },
      "source": [
        "???"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAUgHFdn1Xnk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "68c041e2-e225-472d-ca99-64646d0c44aa"
      },
      "source": [
        "!git clone https://github.com/bfelbo/DeepMoji.git"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DeepMoji'...\n",
            "remote: Enumerating objects: 281, done.\u001b[K\n",
            "remote: Total 281 (delta 0), reused 0 (delta 0), pack-reused 281\u001b[K\n",
            "Receiving objects: 100% (281/281), 110.54 MiB | 33.72 MiB/s, done.\n",
            "Resolving deltas: 100% (142/142), done.\n",
            "Checking out files: 100% (66/66), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZXz66rH8KVm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ccbd4f64-abde-4d4c-89a9-8078110ee006"
      },
      "source": [
        "%cd DeepMoji"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DeepMoji\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkfxUB65GG0A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "54b3a6b4-3c42-4ff7-9997-e4a9c67c654a"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdata\u001b[0m/      emoji_overview.png  \u001b[01;34mexamples\u001b[0m/  \u001b[01;34mmodel\u001b[0m/     \u001b[01;34mscripts\u001b[0m/  \u001b[01;34mtests\u001b[0m/\n",
            "\u001b[01;34mdeepmoji\u001b[0m/  emoji_unicode.csv   LICENSE    README.md  setup.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Izot3bbaGSuU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "41404437-54e7-4108-81a8-95233cb30fd4"
      },
      "source": [
        "import sys\n",
        "from os.path import abspath, dirname\n",
        "\n",
        "sys.path.insert(0, '/content/DeepMoji')\n",
        "sys.path.insert(0, '/content/DeepMoji/deepmoji')\n",
        "sys.path.insert(0, '/content/DeepMoji/examples')\n",
        "\n",
        "print(sys.path)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/DeepMoji/examples', '/content/DeepMoji/deepmoji', '/content/DeepMoji', '', '/env/python', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.6/dist-packages/IPython/extensions', '/root/.ipython']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWFsR3NT8l0I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e4e2b1c-2593-4e88-854a-adac794cf922"
      },
      "source": [
        "%cd scripts"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DeepMoji/scripts\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOoLJzFRa_gn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "9086949b-3fa9-4faf-f1da-1df10bedb3f2"
      },
      "source": [
        "from __future__ import print_function\n",
        "import os\n",
        "from subprocess import call\n",
        "\n",
        "curr_folder = os.path.basename(os.path.normpath(os.getcwd()))\n",
        "\n",
        "weights_filename = 'deepmoji_weights.hdf5'\n",
        "weights_folder = 'model'\n",
        "weights_path = '{}/{}'.format(weights_folder, weights_filename)\n",
        "if curr_folder == 'scripts':\n",
        "    weights_path = '../' + weights_path\n",
        "weights_download_link = 'https://www.dropbox.com/s/xqarafsl6a8f9ny/deepmoji_weights.hdf5?dl=0#'\n",
        "\n",
        "\n",
        "MB_FACTOR = float(1 << 20)\n",
        "\n",
        "\n",
        "def prompt():\n",
        "    while True:\n",
        "        valid = {\n",
        "            'y': True,\n",
        "            'ye': True,\n",
        "            'yes': True,\n",
        "            'n': False,\n",
        "            'no': False,\n",
        "        }\n",
        "        if 'TRAVIS' in os.environ:\n",
        "            choice = 'yes'\n",
        "        else:\n",
        "            choice = input().lower()\n",
        "        if choice in valid:\n",
        "            return valid[choice]\n",
        "        else:\n",
        "            print('Please respond with \\'y\\' or \\'n\\' (or \\'yes\\' or \\'no\\')')\n",
        "\n",
        "\n",
        "download = True\n",
        "if os.path.exists(weights_path):\n",
        "    print('Weight file already exists at {}. Would you like to redownload it anyway? [y/n]'.format(weights_path))\n",
        "    download = prompt()\n",
        "    already_exists = True\n",
        "else:\n",
        "    already_exists = False\n",
        "\n",
        "if download:\n",
        "    print('About to download the pretrained weights file from {}'.format(weights_download_link))\n",
        "    if not already_exists:\n",
        "        print('The size of the file is roughly 85MB. Continue? [y/n]')\n",
        "    else:\n",
        "        os.unlink(weights_path)\n",
        "\n",
        "    if already_exists or prompt():\n",
        "        print('Downloading...')\n",
        "\n",
        "        # urllib.urlretrieve(weights_download_link, weights_path)\n",
        "        # with open(weights_path,'wb') as f:\n",
        "        #     f.write(requests.get(weights_download_link).content)\n",
        "\n",
        "        # downloading using wget due to issues with urlretrieve and requests\n",
        "        sys_call = 'wget {} -O {}'.format(weights_download_link, os.path.abspath(weights_path))\n",
        "        print(\"Running system call: {}\".format(sys_call))\n",
        "        call(sys_call, shell=True)\n",
        "\n",
        "        if os.path.getsize(weights_path) / MB_FACTOR < 80:\n",
        "            raise ValueError(\"Download finished, but the resulting file is too small! \" +\n",
        "                             \"It\\'s only {} bytes.\".format(os.path.getsize(weights_path)))\n",
        "        print('Downloaded weights to {}'.format(weights_path))\n",
        "else:\n",
        "    print('Exiting.')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "About to download the pretrained weights file from https://www.dropbox.com/s/xqarafsl6a8f9ny/deepmoji_weights.hdf5?dl=0#\n",
            "The size of the file is roughly 85MB. Continue? [y/n]\n",
            "y\n",
            "Downloading...\n",
            "Running system call: wget https://www.dropbox.com/s/xqarafsl6a8f9ny/deepmoji_weights.hdf5?dl=0# -O /content/DeepMoji/model/deepmoji_weights.hdf5\n",
            "Downloaded weights to model/deepmoji_weights.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrZADvxi80oo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8339f7a6-fd9e-4278-f210-f01cf1d4c4ac"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdata\u001b[0m/      emoji_overview.png  \u001b[01;34mexamples\u001b[0m/  \u001b[01;34mmodel\u001b[0m/     \u001b[01;34mscripts\u001b[0m/  \u001b[01;34mtests\u001b[0m/\n",
            "\u001b[01;34mdeepmoji\u001b[0m/  emoji_unicode.csv   LICENSE    README.md  setup.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9nq3gKfHax7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "outputId": "aeaf8f5a-129e-40f5-8074-a8b56d82776e"
      },
      "source": [
        "!pip3 uninstall -y tensorflow\n",
        "!pip3 install tensorflow==1.13.1"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.2.0rc2:\n",
            "  Successfully uninstalled tensorflow-2.2.0rc2\n",
            "Collecting tensorflow==1.13.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/63/a9fa76de8dffe7455304c4ed635be4aa9c0bacef6e0633d87d5f54530c5c/tensorflow-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (92.5MB)\n",
            "\u001b[K     |████████████████████████████████| 92.5MB 63kB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.9.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.0.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (3.10.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.3.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.12.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.34.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.18.2)\n",
            "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 27.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.8.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.27.2)\n",
            "Collecting tensorboard<1.14.0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 35.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.1) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.13.1) (46.0.0)\n",
            "Collecting mock>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/cd/74/d72daf8dff5b6566db857cfd088907bb0355f5dd2914c4b3ef065c790735/mock-4.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (1.0.1)\n",
            "Installing collected packages: mock, tensorflow-estimator, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.2.0rc0\n",
            "    Uninstalling tensorflow-estimator-2.2.0rc0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0rc0\n",
            "  Found existing installation: tensorboard 2.2.0\n",
            "    Uninstalling tensorboard-2.2.0:\n",
            "      Successfully uninstalled tensorboard-2.2.0\n",
            "Successfully installed mock-4.0.2 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsHN5zsnHXYA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "70b16b1c-ddc5-4c74-e247-04fbb0d81bd2"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yifU9mcKS3uN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        },
        "outputId": "f3934a16-e824-4da4-c9db-86c9836fb800"
      },
      "source": [
        "\"\"\"Trains the DeepMoji architecture on the IMDB sentiment classification task.\n",
        "   This is a simple example of using the architecture without the pretrained model.\n",
        "   The architecture is designed for transfer learning - it should normally\n",
        "   be used with the pretrained model for optimal performance.\n",
        "\"\"\"\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "from keras.preprocessing import sequence\n",
        "from keras.datasets import imdb\n",
        "from deepmoji.model_def import deepmoji_architecture\n",
        "\n",
        "# Seed for reproducibility\n",
        "np.random.seed(1337)\n",
        "\n",
        "batch_size = 256\n",
        "\n",
        "print('Build model...')\n",
        "model = deepmoji_architecture(nb_classes=2, nb_tokens=dictionary_length, maxlen=input_length)\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Train...')\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=10,\n",
        "          validation_data=(x_val, y_val))\n",
        "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build model...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"DeepMoji\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 100)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 100, 256)     2560000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 100, 256)     0           embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bi_lstm_0 (Bidirectional)       (None, 100, 1024)    3149824     activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bi_lstm_1 (Bidirectional)       (None, 100, 1024)    6295552     bi_lstm_0[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 100, 2304)    0           bi_lstm_1[0][0]                  \n",
            "                                                                 bi_lstm_0[0][0]                  \n",
            "                                                                 activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "attlayer (AttentionWeightedAver (None, 2304)         2304        concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "softmax (Dense)                 (None, 1)            2305        attlayer[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 12,009,985\n",
            "Trainable params: 12,009,985\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Train...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/10\n",
            "20000/20000 [==============================] - 4250s 212ms/step - loss: 0.5530 - acc: 0.7288 - val_loss: 0.4592 - val_acc: 0.7828\n",
            "Epoch 2/10\n",
            " 9472/20000 [=============>................] - ETA: 34:30 - loss: 0.3568 - acc: 0.8464"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}