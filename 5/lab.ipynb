{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "lab.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "WZfImSn8R0d0",
        "colab_type": "text"
      },
      "source": [
        "<b>Google Colab</b> <a href=\"https://colab.research.google.com/github/kirillzyusko/deeplearning/blob/master/5/lab.ipynb\">link</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABNIE8m59gGm",
        "colab_type": "text"
      },
      "source": [
        "Authorize google + kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBIxqfvSR0d2",
        "colab_type": "code",
        "outputId": "217b311b-329d-4138-adc9-e4f4ea40d924",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from googleapiclient.discovery import build\n",
        "import io, os\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "results = drive_service.files().list(\n",
        "        q=\"name = 'kaggle.json'\", fields=\"files(id)\").execute()\n",
        "kaggle_api_key = results.get('files', [])\n",
        "filename = \"/content/.kaggle/kaggle.json\"\n",
        "os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "request = drive_service.files().get_media(fileId=kaggle_api_key[0]['id'])\n",
        "fh = io.FileIO(filename, 'wb')\n",
        "downloader = MediaIoBaseDownload(fh, request)\n",
        "done = False\n",
        "while done is False:\n",
        "    status, done = downloader.next_chunk()\n",
        "    print(\"Download %d%%.\" % int(status.progress() * 100))\n",
        "os.chmod(filename, 600)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Download 100%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUnvOmrY-uOx",
        "colab_type": "text"
      },
      "source": [
        "Be sure, that we authorized and have an access to kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHH44E0AR0d5",
        "colab_type": "code",
        "outputId": "0fe9c194-1b05-4fe1-e121-2b915d2292db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%ls /content/.kaggle/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;32mkaggle.json\u001b[0m*\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dsvy8e5J-2DS",
        "colab_type": "text"
      },
      "source": [
        "# **Part 1: Download dataset, extract, split, check data distribution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWC-mL6h9_JR",
        "colab_type": "code",
        "outputId": "a7f2dc7f-5588-4586-8976-eba1e0cfeffc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download  -c dogs-vs-cats -p /content/kaggle/dogscats"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading sampleSubmission.csv to /content/kaggle/dogscats\n",
            "  0% 0.00/86.8k [00:00<?, ?B/s]\n",
            "100% 86.8k/86.8k [00:00<00:00, 81.9MB/s]\n",
            "Downloading train.zip to /content/kaggle/dogscats\n",
            " 99% 537M/543M [00:15<00:00, 23.3MB/s]\n",
            "100% 543M/543M [00:15<00:00, 36.0MB/s]\n",
            "Downloading test1.zip to /content/kaggle/dogscats\n",
            " 97% 263M/271M [00:04<00:00, 65.7MB/s]\n",
            "100% 271M/271M [00:04<00:00, 57.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FpbBukR-8kJ",
        "colab_type": "text"
      },
      "source": [
        "Extract .zip\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hebfxSN_U2o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip kaggle/dogscats/train.zip -d train\n",
        "!unzip kaggle/dogscats/test1.zip -d test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtNiv6ozrnZk",
        "colab_type": "code",
        "outputId": "c90ca94d-d323-41c3-ea4d-3bf84b41c51d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json  \u001b[0m\u001b[01;34mkaggle\u001b[0m/  \u001b[01;34msample_data\u001b[0m/  \u001b[01;34mtest\u001b[0m/  \u001b[01;34mtrain\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2_AYHk5rsTb",
        "colab_type": "code",
        "outputId": "830b6c58-1d11-4bcb-dd9a-b2c5848b8800",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "TRAIN_PATH = './train/train'\n",
        "TEST_PATH = './test/test1'\n",
        "\n",
        "filenames = os.listdir(TRAIN_PATH)\n",
        "categories = []\n",
        "for filename in filenames:\n",
        "    category = filename.split('.')[0]\n",
        "    if category == 'dog':\n",
        "        categories.append(1)\n",
        "    else:\n",
        "        categories.append(0)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'filename': filenames,\n",
        "    'category': categories\n",
        "})\n",
        "\n",
        "df[\"category\"] = df[\"category\"].replace({0: 'cat', 1: 'dog'}) \n",
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cat.2910.jpg</td>\n",
              "      <td>cat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cat.3176.jpg</td>\n",
              "      <td>cat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cat.6647.jpg</td>\n",
              "      <td>cat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dog.1106.jpg</td>\n",
              "      <td>dog</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>cat.6265.jpg</td>\n",
              "      <td>cat</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       filename category\n",
              "0  cat.2910.jpg      cat\n",
              "1  cat.3176.jpg      cat\n",
              "2  cat.6647.jpg      cat\n",
              "3  dog.1106.jpg      dog\n",
              "4  cat.6265.jpg      cat"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHyb3POgrzna",
        "colab_type": "code",
        "outputId": "868bb430-f9d9-4ab6-ee37-a74461f91937",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        }
      },
      "source": [
        "df['category'].value_counts().plot.bar()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2fdcf0a4e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEBCAYAAACaHMnBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQJKEYSBJwjCQJAH/B4ufjQ3n+SNAAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YX-kMDkqu7ps",
        "colab_type": "text"
      },
      "source": [
        "Train/Dev split\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FgMZAnjuW2p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, val = train_test_split(df, test_size=0.20, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqrP8Eccu-uq",
        "colab_type": "text"
      },
      "source": [
        "Check data distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UuY0TQluzP3",
        "colab_type": "code",
        "outputId": "4e8f9fe8-0bc8-467c-d127-85624f0dc77a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        }
      },
      "source": [
        "train['category'].value_counts().plot.bar()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2fcaf9a4e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEBCAYAAACaHMnBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEvB/Imvm6eXMolwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASzyO1gdu02a",
        "colab_type": "code",
        "outputId": "fdb449ca-10f1-482e-8776-b07a713a6b61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        }
      },
      "source": [
        "val['category'].value_counts().plot.bar()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2fcad679b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEBCAYAAACUmXXrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVBo4m6lzBbo",
        "colab_type": "text"
      },
      "source": [
        "Use `ImageDataGenerator` in order to reduce data memory consumption (just with rescaling for improving speed of learning)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XilH3-zfzAmu",
        "colab_type": "code",
        "outputId": "50d2da3d-0d92-4508-ae42-982b0059e9d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "\n",
        "# train\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "total_train = train.shape[0]\n",
        "total_validate = val.shape[0]\n",
        "batch_size = 32  # since Andrew Ng told, that better use 2^n\n",
        "\n",
        "IMAGE_WIDTH=128\n",
        "IMAGE_HEIGHT=128\n",
        "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
        "IMAGE_CHANNELS=3\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    train, \n",
        "    TRAIN_PATH, \n",
        "    x_col='filename',\n",
        "    y_col='category',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# validation\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_generator = validation_datagen.flow_from_dataframe(\n",
        "    val, \n",
        "    TRAIN_PATH, \n",
        "    x_col='filename',\n",
        "    y_col='category',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 20000 validated image filenames belonging to 2 classes.\n",
            "Found 5000 validated image filenames belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcP_Jbl3vNOV",
        "colab_type": "text"
      },
      "source": [
        "# TODO: implement test set preparation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3h8l0LYXvI30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjcNwIyJvU0V",
        "colab_type": "text"
      },
      "source": [
        "# **Part 2: DNN architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85w3ilHfvscC",
        "colab_type": "code",
        "outputId": "bb812e07-2fd6-40fb-a370-2b9363e70038",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
        "\n",
        "IMAGE_WIDTH=128\n",
        "IMAGE_HEIGHT=128\n",
        "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
        "IMAGE_CHANNELS=3\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2, activation='softmax')) # 2 classes: dog and cat\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 126, 126, 32)      896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 126, 126, 32)      128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 63, 63, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 61, 61, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 61, 61, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 30, 30, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 28, 28, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 28, 28, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               12845568  \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 12,942,786\n",
            "Trainable params: 12,941,314\n",
            "Non-trainable params: 1,472\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpOKjQ4axlqS",
        "colab_type": "code",
        "outputId": "70a90194-38de-436f-d9d5-0e512aeea586",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit_generator(\n",
        "    train_generator, \n",
        "    epochs=30,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=total_validate//batch_size,\n",
        "    steps_per_epoch=total_train//batch_size,\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/30\n",
            "625/625 [==============================] - 74s 118ms/step - loss: 0.7093 - acc: 0.6717 - val_loss: 0.5103 - val_acc: 0.7496\n",
            "Epoch 2/30\n",
            "625/625 [==============================] - 66s 105ms/step - loss: 0.4665 - acc: 0.7805 - val_loss: 0.6416 - val_acc: 0.7341\n",
            "Epoch 3/30\n",
            "625/625 [==============================] - 65s 104ms/step - loss: 0.3966 - acc: 0.8262 - val_loss: 0.3763 - val_acc: 0.8353\n",
            "Epoch 4/30\n",
            "625/625 [==============================] - 65s 104ms/step - loss: 0.3345 - acc: 0.8579 - val_loss: 0.4270 - val_acc: 0.8072\n",
            "Epoch 5/30\n",
            "625/625 [==============================] - 68s 109ms/step - loss: 0.2936 - acc: 0.8756 - val_loss: 0.4239 - val_acc: 0.8152\n",
            "Epoch 6/30\n",
            "625/625 [==============================] - 72s 116ms/step - loss: 0.2611 - acc: 0.8909 - val_loss: 0.4299 - val_acc: 0.8156\n",
            "Epoch 7/30\n",
            "625/625 [==============================] - 72s 115ms/step - loss: 0.2280 - acc: 0.9082 - val_loss: 0.5841 - val_acc: 0.7260\n",
            "Epoch 8/30\n",
            "625/625 [==============================] - 70s 113ms/step - loss: 0.2104 - acc: 0.9172 - val_loss: 0.4382 - val_acc: 0.8118\n",
            "Epoch 9/30\n",
            "625/625 [==============================] - 68s 108ms/step - loss: 0.1863 - acc: 0.9271 - val_loss: 0.3903 - val_acc: 0.8436\n",
            "Epoch 10/30\n",
            "625/625 [==============================] - 70s 111ms/step - loss: 0.1673 - acc: 0.9358 - val_loss: 0.3700 - val_acc: 0.8390\n",
            "Epoch 11/30\n",
            "625/625 [==============================] - 69s 110ms/step - loss: 0.1590 - acc: 0.9407 - val_loss: 0.4251 - val_acc: 0.8090\n",
            "Epoch 12/30\n",
            "625/625 [==============================] - 69s 110ms/step - loss: 0.1414 - acc: 0.9465 - val_loss: 0.5320 - val_acc: 0.8174\n",
            "Epoch 13/30\n",
            "625/625 [==============================] - 69s 110ms/step - loss: 0.1334 - acc: 0.9488 - val_loss: 1.7060 - val_acc: 0.7536\n",
            "Epoch 14/30\n",
            "625/625 [==============================] - 70s 112ms/step - loss: 0.1262 - acc: 0.9529 - val_loss: 0.5204 - val_acc: 0.8295\n",
            "Epoch 15/30\n",
            "625/625 [==============================] - 70s 111ms/step - loss: 0.1219 - acc: 0.9547 - val_loss: 0.3633 - val_acc: 0.8482\n",
            "Epoch 16/30\n",
            "625/625 [==============================] - 70s 112ms/step - loss: 0.1203 - acc: 0.9568 - val_loss: 0.3989 - val_acc: 0.8579\n",
            "Epoch 17/30\n",
            "625/625 [==============================] - 68s 109ms/step - loss: 0.1136 - acc: 0.9584 - val_loss: 0.3609 - val_acc: 0.8740\n",
            "Epoch 18/30\n",
            "625/625 [==============================] - 68s 109ms/step - loss: 0.1076 - acc: 0.9618 - val_loss: 0.5287 - val_acc: 0.8643\n",
            "Epoch 19/30\n",
            "625/625 [==============================] - 68s 109ms/step - loss: 0.1069 - acc: 0.9612 - val_loss: 0.4021 - val_acc: 0.8531\n",
            "Epoch 20/30\n",
            "625/625 [==============================] - 66s 106ms/step - loss: 0.1011 - acc: 0.9638 - val_loss: 0.3575 - val_acc: 0.8736\n",
            "Epoch 21/30\n",
            "625/625 [==============================] - 67s 108ms/step - loss: 0.0922 - acc: 0.9663 - val_loss: 0.4282 - val_acc: 0.8714\n",
            "Epoch 22/30\n",
            "625/625 [==============================] - 68s 108ms/step - loss: 0.0924 - acc: 0.9668 - val_loss: 0.5847 - val_acc: 0.8514\n",
            "Epoch 23/30\n",
            "625/625 [==============================] - 67s 108ms/step - loss: 0.0851 - acc: 0.9688 - val_loss: 0.7124 - val_acc: 0.8347\n",
            "Epoch 24/30\n",
            "625/625 [==============================] - 67s 107ms/step - loss: 0.0912 - acc: 0.9682 - val_loss: 0.5980 - val_acc: 0.8569\n",
            "Epoch 25/30\n",
            "625/625 [==============================] - 68s 108ms/step - loss: 0.0981 - acc: 0.9671 - val_loss: 0.5196 - val_acc: 0.8561\n",
            "Epoch 26/30\n",
            "625/625 [==============================] - 68s 108ms/step - loss: 0.0864 - acc: 0.9688 - val_loss: 0.4742 - val_acc: 0.8639\n",
            "Epoch 27/30\n",
            "625/625 [==============================] - 68s 109ms/step - loss: 0.0833 - acc: 0.9707 - val_loss: 0.4433 - val_acc: 0.8780\n",
            "Epoch 28/30\n",
            "625/625 [==============================] - 68s 109ms/step - loss: 0.0780 - acc: 0.9736 - val_loss: 0.4612 - val_acc: 0.8814\n",
            "Epoch 29/30\n",
            "625/625 [==============================] - 68s 108ms/step - loss: 0.0863 - acc: 0.9702 - val_loss: 0.7356 - val_acc: 0.8305\n",
            "Epoch 30/30\n",
            "625/625 [==============================] - 67s 107ms/step - loss: 0.0793 - acc: 0.9715 - val_loss: 0.5100 - val_acc: 0.8611\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMykkvrHHRzW",
        "colab_type": "text"
      },
      "source": [
        "# **Part 3: Add data augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQA2ySMDHZhU",
        "colab_type": "code",
        "outputId": "ac94f65d-4f57-4dbc-9deb-388bcf7f7b6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_datagen_aug = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    rescale=1./255,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1\n",
        ")\n",
        "\n",
        "train_generator_aug = train_datagen_aug.flow_from_dataframe(\n",
        "    train, \n",
        "    TRAIN_PATH, \n",
        "    x_col='filename',\n",
        "    y_col='category',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 20000 validated image filenames belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCSZ0fjdH8B_",
        "colab_type": "text"
      },
      "source": [
        "And train NN again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRJR_XLRH7Qn",
        "colab_type": "code",
        "outputId": "3b5df553-5f02-4986-a9d4-9044e102cc08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit_generator(\n",
        "    train_generator_aug, \n",
        "    epochs=30,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=total_validate//batch_size,\n",
        "    steps_per_epoch=total_train//batch_size,\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "625/625 [==============================] - 134s 214ms/step - loss: 0.5200 - acc: 0.8266 - val_loss: 0.3236 - val_acc: 0.8718\n",
            "Epoch 2/30\n",
            "625/625 [==============================] - 131s 209ms/step - loss: 0.3631 - acc: 0.8474 - val_loss: 0.2926 - val_acc: 0.8804\n",
            "Epoch 3/30\n",
            "625/625 [==============================] - 130s 209ms/step - loss: 0.3352 - acc: 0.8573 - val_loss: 0.4228 - val_acc: 0.8434\n",
            "Epoch 4/30\n",
            "625/625 [==============================] - 132s 211ms/step - loss: 0.3273 - acc: 0.8595 - val_loss: 0.9596 - val_acc: 0.7651\n",
            "Epoch 5/30\n",
            "625/625 [==============================] - 132s 211ms/step - loss: 0.3155 - acc: 0.8661 - val_loss: 0.3775 - val_acc: 0.8484\n",
            "Epoch 6/30\n",
            "625/625 [==============================] - 132s 211ms/step - loss: 0.3043 - acc: 0.8717 - val_loss: 0.3074 - val_acc: 0.8776\n",
            "Epoch 7/30\n",
            "625/625 [==============================] - 136s 218ms/step - loss: 0.2946 - acc: 0.8777 - val_loss: 0.3392 - val_acc: 0.8706\n",
            "Epoch 8/30\n",
            "625/625 [==============================] - 137s 219ms/step - loss: 0.3009 - acc: 0.8731 - val_loss: 0.2794 - val_acc: 0.8915\n",
            "Epoch 9/30\n",
            "625/625 [==============================] - 132s 211ms/step - loss: 0.2875 - acc: 0.8776 - val_loss: 0.7670 - val_acc: 0.8205\n",
            "Epoch 10/30\n",
            "625/625 [==============================] - 132s 211ms/step - loss: 0.2885 - acc: 0.8816 - val_loss: 0.2876 - val_acc: 0.8867\n",
            "Epoch 11/30\n",
            "625/625 [==============================] - 132s 211ms/step - loss: 0.2856 - acc: 0.8799 - val_loss: 0.2669 - val_acc: 0.8983\n",
            "Epoch 12/30\n",
            "625/625 [==============================] - 132s 212ms/step - loss: 0.2786 - acc: 0.8831 - val_loss: 0.2242 - val_acc: 0.9088\n",
            "Epoch 13/30\n",
            "625/625 [==============================] - 129s 206ms/step - loss: 0.2752 - acc: 0.8848 - val_loss: 0.2494 - val_acc: 0.9036\n",
            "Epoch 14/30\n",
            "625/625 [==============================] - 128s 205ms/step - loss: 0.2674 - acc: 0.8886 - val_loss: 0.2941 - val_acc: 0.8913\n",
            "Epoch 15/30\n",
            "625/625 [==============================] - 133s 212ms/step - loss: 0.2745 - acc: 0.8849 - val_loss: 0.3130 - val_acc: 0.8829\n",
            "Epoch 16/30\n",
            "625/625 [==============================] - 136s 218ms/step - loss: 0.2676 - acc: 0.8881 - val_loss: 0.2426 - val_acc: 0.9096\n",
            "Epoch 17/30\n",
            "625/625 [==============================] - 137s 219ms/step - loss: 0.2694 - acc: 0.8854 - val_loss: 0.5295 - val_acc: 0.8211\n",
            "Epoch 18/30\n",
            "625/625 [==============================] - 140s 224ms/step - loss: 0.2698 - acc: 0.8886 - val_loss: 0.3058 - val_acc: 0.8875\n",
            "Epoch 19/30\n",
            "625/625 [==============================] - 136s 217ms/step - loss: 0.2599 - acc: 0.8902 - val_loss: 0.2499 - val_acc: 0.9082\n",
            "Epoch 20/30\n",
            "625/625 [==============================] - 134s 214ms/step - loss: 0.2587 - acc: 0.8912 - val_loss: 0.3746 - val_acc: 0.8482\n",
            "Epoch 21/30\n",
            "625/625 [==============================] - 134s 214ms/step - loss: 0.2597 - acc: 0.8939 - val_loss: 0.2646 - val_acc: 0.8992\n",
            "Epoch 22/30\n",
            "625/625 [==============================] - 133s 213ms/step - loss: 0.2599 - acc: 0.8926 - val_loss: 0.2705 - val_acc: 0.8927\n",
            "Epoch 23/30\n",
            "625/625 [==============================] - 132s 212ms/step - loss: 0.2558 - acc: 0.8956 - val_loss: 0.2535 - val_acc: 0.8963\n",
            "Epoch 24/30\n",
            "625/625 [==============================] - 131s 209ms/step - loss: 0.2500 - acc: 0.8975 - val_loss: 0.2782 - val_acc: 0.9012\n",
            "Epoch 25/30\n",
            "625/625 [==============================] - 130s 209ms/step - loss: 0.2458 - acc: 0.8989 - val_loss: 0.2445 - val_acc: 0.9044\n",
            "Epoch 26/30\n",
            "625/625 [==============================] - 131s 209ms/step - loss: 0.2502 - acc: 0.8986 - val_loss: 0.3024 - val_acc: 0.8706\n",
            "Epoch 27/30\n",
            "625/625 [==============================] - 132s 212ms/step - loss: 0.2499 - acc: 0.8962 - val_loss: 0.2517 - val_acc: 0.9006\n",
            "Epoch 28/30\n",
            "625/625 [==============================] - 131s 210ms/step - loss: 0.2389 - acc: 0.9021 - val_loss: 0.2784 - val_acc: 0.8881\n",
            "Epoch 29/30\n",
            "625/625 [==============================] - 129s 207ms/step - loss: 0.2427 - acc: 0.8994 - val_loss: 0.5702 - val_acc: 0.8311\n",
            "Epoch 30/30\n",
            "625/625 [==============================] - 127s 203ms/step - loss: 0.2384 - acc: 0.9031 - val_loss: 0.2329 - val_acc: 0.9128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWJ2k55HQq59",
        "colab_type": "text"
      },
      "source": [
        "# **Part 4: using VGG16**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PICmCUwkSoF-",
        "colab_type": "text"
      },
      "source": [
        "Define model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBHEH7LPQ3tF",
        "colab_type": "code",
        "outputId": "a66d6afc-2a71-4fc0-c07c-452e04c4b6e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.applications.vgg16 import VGG16\n",
        "\n",
        "# load model\n",
        "vgg = VGG16(include_top=False, input_shape=(224, 224, 3))\n",
        "# mark loaded layers as not trainable\n",
        "for layer in vgg.layers:\n",
        "\tlayer.trainable = False\n",
        "\n",
        "# define a new output layer to connect with the last fc layer in vgg\n",
        "x = Flatten()(vgg.layers[-1].output)\n",
        "class1 = Dense(512, activation='relu', kernel_initializer='he_uniform')(x)\n",
        "bn = BatchNormalization()(class1)\n",
        "do = Dropout(0.5)(bn)\n",
        "output_layer = Dense(2, activation='softmax', name='predictions')(do)\n",
        "\n",
        "# combine the original VGG model with the new output layer\n",
        "vgg = Model(inputs=vgg.input, outputs=output_layer)\n",
        "\n",
        "vgg.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_generator_aug, \n",
        "    epochs=30,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=total_validate//batch_size,\n",
        "    steps_per_epoch=total_train//batch_size,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "625/625 [==============================] - 133s 213ms/step - loss: 0.3228 - acc: 0.8816 - val_loss: 0.2928 - val_acc: 0.8718\n",
            "Epoch 2/30\n",
            "625/625 [==============================] - 131s 210ms/step - loss: 0.2766 - acc: 0.8890 - val_loss: 0.2544 - val_acc: 0.9004\n",
            "Epoch 3/30\n",
            "625/625 [==============================] - 131s 209ms/step - loss: 0.2596 - acc: 0.8937 - val_loss: 0.2163 - val_acc: 0.9163\n",
            "Epoch 4/30\n",
            "625/625 [==============================] - 129s 207ms/step - loss: 0.2578 - acc: 0.8943 - val_loss: 0.2192 - val_acc: 0.9193\n",
            "Epoch 5/30\n",
            "625/625 [==============================] - 130s 208ms/step - loss: 0.2440 - acc: 0.9004 - val_loss: 0.2389 - val_acc: 0.9175\n",
            "Epoch 6/30\n",
            "625/625 [==============================] - 130s 208ms/step - loss: 0.2401 - acc: 0.9024 - val_loss: 0.2254 - val_acc: 0.9171\n",
            "Epoch 7/30\n",
            "625/625 [==============================] - 131s 209ms/step - loss: 0.2475 - acc: 0.8982 - val_loss: 0.2491 - val_acc: 0.9209\n",
            "Epoch 8/30\n",
            "625/625 [==============================] - 129s 207ms/step - loss: 0.2425 - acc: 0.8999 - val_loss: 0.2763 - val_acc: 0.9012\n",
            "Epoch 9/30\n",
            "625/625 [==============================] - 129s 206ms/step - loss: 0.2418 - acc: 0.8995 - val_loss: 0.2169 - val_acc: 0.9124\n",
            "Epoch 10/30\n",
            "625/625 [==============================] - 129s 207ms/step - loss: 0.2445 - acc: 0.8991 - val_loss: 0.2278 - val_acc: 0.9189\n",
            "Epoch 11/30\n",
            "625/625 [==============================] - 130s 207ms/step - loss: 0.2375 - acc: 0.9021 - val_loss: 0.2169 - val_acc: 0.9279\n",
            "Epoch 12/30\n",
            "625/625 [==============================] - 130s 209ms/step - loss: 0.2434 - acc: 0.8986 - val_loss: 0.2333 - val_acc: 0.9287\n",
            "Epoch 13/30\n",
            "625/625 [==============================] - 135s 216ms/step - loss: 0.2342 - acc: 0.9049 - val_loss: 0.4467 - val_acc: 0.8064\n",
            "Epoch 14/30\n",
            "625/625 [==============================] - 136s 217ms/step - loss: 0.2326 - acc: 0.9058 - val_loss: 0.2448 - val_acc: 0.9002\n",
            "Epoch 15/30\n",
            "625/625 [==============================] - 132s 212ms/step - loss: 0.2343 - acc: 0.9033 - val_loss: 0.2657 - val_acc: 0.8957\n",
            "Epoch 16/30\n",
            "625/625 [==============================] - 131s 209ms/step - loss: 0.2276 - acc: 0.9064 - val_loss: 0.2768 - val_acc: 0.8947\n",
            "Epoch 17/30\n",
            "625/625 [==============================] - 130s 207ms/step - loss: 0.2326 - acc: 0.9062 - val_loss: 0.4921 - val_acc: 0.8591\n",
            "Epoch 18/30\n",
            "625/625 [==============================] - 129s 206ms/step - loss: 0.2331 - acc: 0.9038 - val_loss: 0.2172 - val_acc: 0.9223\n",
            "Epoch 19/30\n",
            "625/625 [==============================] - 129s 207ms/step - loss: 0.2241 - acc: 0.9098 - val_loss: 0.2215 - val_acc: 0.9134\n",
            "Epoch 20/30\n",
            "625/625 [==============================] - 131s 210ms/step - loss: 0.2306 - acc: 0.9070 - val_loss: 0.2299 - val_acc: 0.9255\n",
            "Epoch 21/30\n",
            "625/625 [==============================] - 133s 212ms/step - loss: 0.2273 - acc: 0.9090 - val_loss: 0.2468 - val_acc: 0.9026\n",
            "Epoch 22/30\n",
            "625/625 [==============================] - 131s 209ms/step - loss: 0.2163 - acc: 0.9109 - val_loss: 0.2996 - val_acc: 0.8909\n",
            "Epoch 23/30\n",
            "625/625 [==============================] - 129s 207ms/step - loss: 0.2294 - acc: 0.9072 - val_loss: 0.2423 - val_acc: 0.9054\n",
            "Epoch 24/30\n",
            "625/625 [==============================] - 129s 207ms/step - loss: 0.2214 - acc: 0.9103 - val_loss: 0.3504 - val_acc: 0.8671\n",
            "Epoch 25/30\n",
            "625/625 [==============================] - 129s 206ms/step - loss: 0.2228 - acc: 0.9105 - val_loss: 0.2319 - val_acc: 0.9138\n",
            "Epoch 26/30\n",
            "625/625 [==============================] - 129s 207ms/step - loss: 0.2231 - acc: 0.9083 - val_loss: 0.2417 - val_acc: 0.9080\n",
            "Epoch 27/30\n",
            "625/625 [==============================] - 128s 205ms/step - loss: 0.2251 - acc: 0.9081 - val_loss: 0.2102 - val_acc: 0.9283\n",
            "Epoch 28/30\n",
            "625/625 [==============================] - 128s 205ms/step - loss: 0.2177 - acc: 0.9116 - val_loss: 0.3849 - val_acc: 0.8645\n",
            "Epoch 29/30\n",
            "625/625 [==============================] - 128s 205ms/step - loss: 0.2205 - acc: 0.9093 - val_loss: 0.2145 - val_acc: 0.9231\n",
            "Epoch 30/30\n",
            "625/625 [==============================] - 128s 205ms/step - loss: 0.2196 - acc: 0.9110 - val_loss: 0.3916 - val_acc: 0.8537\n",
            "<keras.callbacks.History object at 0x7fb91bc02c50>\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}