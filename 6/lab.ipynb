{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "lab.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "WZfImSn8R0d0",
        "colab_type": "text"
      },
      "source": [
        "<b>Google Colab</b> <a href=\"https://colab.research.google.com/github/kirillzyusko/deeplearning/blob/master/6/lab.ipynb\">link</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jALamvtBs_59",
        "colab_type": "text"
      },
      "source": [
        "Authorize google + kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBIxqfvSR0d2",
        "colab_type": "code",
        "outputId": "59b3a981-252d-4441-8252-47cb3b9cbdda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from googleapiclient.discovery import build\n",
        "import io, os\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "results = drive_service.files().list(\n",
        "        q=\"name = 'kaggle.json'\", fields=\"files(id)\").execute()\n",
        "kaggle_api_key = results.get('files', [])\n",
        "filename = \"/content/.kaggle/kaggle.json\"\n",
        "os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "request = drive_service.files().get_media(fileId=kaggle_api_key[0]['id'])\n",
        "fh = io.FileIO(filename, 'wb')\n",
        "downloader = MediaIoBaseDownload(fh, request)\n",
        "done = False\n",
        "while done is False:\n",
        "    status, done = downloader.next_chunk()\n",
        "    print(\"Download %d%%.\" % int(status.progress() * 100))\n",
        "os.chmod(filename, 600)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Download 100%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRXF9HEfw-Lq",
        "colab_type": "text"
      },
      "source": [
        "Be sure, that we authorized and have an access to kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHH44E0AR0d5",
        "colab_type": "code",
        "outputId": "dc1cf861-e352-44cd-eae5-1c02646237e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%ls /content/.kaggle/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;32mkaggle.json\u001b[0m*\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scuK4S5oxDjd",
        "colab_type": "text"
      },
      "source": [
        "# **Part 1: Download dataset, extract, split, check data distribution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGGxcFMNxLuf",
        "colab_type": "code",
        "outputId": "6d65c35d-0568-4f65-8d9b-0c39273f8bd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download datamunge/sign-language-mnist -p /content/kaggle/signlanguage"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading sign-language-mnist.zip to /content/kaggle/signlanguage\n",
            " 78% 49.0M/62.6M [00:02<00:01, 12.9MB/s]\n",
            "100% 62.6M/62.6M [00:02<00:00, 23.3MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrCRUpSRxjGY",
        "colab_type": "text"
      },
      "source": [
        "Extract .zip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vqOKF6azu8E",
        "colab_type": "code",
        "outputId": "30c24168-b99b-4cec-b378-cb48a6bfac5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "!unzip kaggle/signlanguage/sign-language-mnist.zip -d data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  kaggle/signlanguage/sign-language-mnist.zip\n",
            "  inflating: data/amer_sign2.png     \n",
            "  inflating: data/amer_sign3.png     \n",
            "  inflating: data/american_sign_language.PNG  \n",
            "  inflating: data/sign_mnist_test.csv  \n",
            "  inflating: data/sign_mnist_test/sign_mnist_test.csv  \n",
            "  inflating: data/sign_mnist_train.csv  \n",
            "  inflating: data/sign_mnist_train/sign_mnist_train.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXejvzHg0bs8",
        "colab_type": "code",
        "outputId": "1c4d0939-6f86-4ec1-cc4b-6e342070b7c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json  \u001b[0m\u001b[01;34mdata\u001b[0m/  \u001b[01;34mkaggle\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMvk2CF40ieg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "TRAIN_PATH = './data/sign_mnist_train.csv'\n",
        "TEST_PATH = './data/sign_mnist_test.csv'\n",
        "\n",
        "IMAGE_WIDTH=28\n",
        "IMAGE_HEIGHT=28\n",
        "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
        "IMAGE_CHANNELS=1\n",
        "\n",
        "train = pd.read_csv(TRAIN_PATH)\n",
        "test = pd.read_csv(TEST_PATH)\n",
        "\n",
        "train, val = train_test_split(train, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "def split_dataset_to_x_y(df):\n",
        "    y = pd.concat([df['label'], pd.get_dummies(df['label'], prefix='label')], axis=1)\n",
        "    df.drop(['label'], axis=1, inplace=True)\n",
        "    y.drop(['label'], axis=1, inplace=True)\n",
        "    X = (df / 255).values.reshape((df.shape[0], IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS))  # data scaling & reshaping\n",
        "\n",
        "    return X, y\n",
        "\n",
        "\n",
        "X_train, y_train = split_dataset_to_x_y(train)\n",
        "X_val, y_val = split_dataset_to_x_y(val)\n",
        "X_test, y_test = split_dataset_to_x_y(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WO6wDC9XMjNP",
        "colab_type": "text"
      },
      "source": [
        "Check data distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDZwfbvhMz8o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "d611de25-ee07-4757-f3a4-d90617d78e7b"
      },
      "source": [
        "y_test.value_counts().plot.bar()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5cb63ed550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD7CAYAAACRxdTpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUoUMd0mq0P8DtNN9iUuh27UAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsUNBunlM9Bk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "10183760-1ff5-4f79-d7d3-cf8d06d3e4f4"
      },
      "source": [
        "y_val.value_counts().plot.bar()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5cb4ce1eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD7CAYAAACRxdTpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlljl4QIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5h6wx_p0NBRW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "eb390097-b0bd-432f-fea5-30f6b56f855b"
      },
      "source": [
        "y_train.value_counts().plot.bar()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5cb4c5d940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD7CAYAAACG50QgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jx9JdwO0NLOY",
        "colab_type": "text"
      },
      "source": [
        "# **Part 2: DNN model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCj7TIb6NO5R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "a484da77-8b96-43e7-b1c5-c0e04d75e4a4"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
        "\n",
        "LABELS = len(set(y_train))\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(LABELS, activation='softmax')) # 2 classes: dog and cat\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.save_weights('initial.h5')"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_20 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "batch_normalization_27 (Batc (None, 26, 26, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_28 (Batc (None, 11, 11, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 3, 3, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_29 (Batc (None, 3, 3, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_22 (MaxPooling (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 512)               66048     \n",
            "_________________________________________________________________\n",
            "batch_normalization_30 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 24)                12312     \n",
            "=================================================================\n",
            "Total params: 173,976\n",
            "Trainable params: 172,504\n",
            "Non-trainable params: 1,472\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifky2VHCOYJ6",
        "colab_type": "text"
      },
      "source": [
        "Train without data augmentation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWFivKKXOb8H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cb2deb47-5e9e-4b83-e8c1-0a5c21d0c359"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator()\n",
        "\n",
        "# compute quantities required for featurewise normalization\n",
        "# (std, mean, and principal components if ZCA whitening is applied)\n",
        "datagen.fit(X_train)\n",
        "\n",
        "model.load_weights('initial.h5')\n",
        "# fits the model on batches:\n",
        "model.fit_generator(\n",
        "    datagen.flow(X_train, y_train, batch_size=32),\n",
        "    steps_per_epoch=len(X_train) / 32,\n",
        "    validation_data=datagen.flow(X_val, y_val),\n",
        "    validation_steps=len(X_val) / 32,\n",
        "    epochs=30\n",
        ")"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "687/686 [==============================] - 7s 11ms/step - loss: 1.2216 - acc: 0.6321 - val_loss: 0.1633 - val_acc: 0.9445\n",
            "Epoch 2/30\n",
            "687/686 [==============================] - 7s 11ms/step - loss: 0.2422 - acc: 0.9202 - val_loss: 0.0158 - val_acc: 0.9978\n",
            "Epoch 3/30\n",
            "687/686 [==============================] - 7s 11ms/step - loss: 0.1168 - acc: 0.9619 - val_loss: 0.0688 - val_acc: 0.9765\n",
            "Epoch 4/30\n",
            "687/686 [==============================] - 7s 11ms/step - loss: 0.0794 - acc: 0.9744 - val_loss: 0.0070 - val_acc: 0.9976\n",
            "Epoch 5/30\n",
            "687/686 [==============================] - 7s 10ms/step - loss: 0.0557 - acc: 0.9812 - val_loss: 0.0118 - val_acc: 0.9969\n",
            "Epoch 6/30\n",
            "687/686 [==============================] - 7s 11ms/step - loss: 0.0543 - acc: 0.9815 - val_loss: 0.0138 - val_acc: 0.9956\n",
            "Epoch 7/30\n",
            "687/686 [==============================] - 7s 10ms/step - loss: 0.0456 - acc: 0.9857 - val_loss: 0.0087 - val_acc: 0.9967\n",
            "Epoch 8/30\n",
            "687/686 [==============================] - 7s 10ms/step - loss: 0.0386 - acc: 0.9870 - val_loss: 0.0209 - val_acc: 0.9942\n",
            "Epoch 9/30\n",
            "687/686 [==============================] - 7s 10ms/step - loss: 0.0415 - acc: 0.9861 - val_loss: 0.0839 - val_acc: 0.9749\n",
            "Epoch 10/30\n",
            "687/686 [==============================] - 7s 11ms/step - loss: 0.0368 - acc: 0.9883 - val_loss: 0.0527 - val_acc: 0.9814\n",
            "Epoch 11/30\n",
            "687/686 [==============================] - 7s 10ms/step - loss: 0.0313 - acc: 0.9899 - val_loss: 1.2744e-04 - val_acc: 1.0000\n",
            "Epoch 12/30\n",
            "687/686 [==============================] - 8s 11ms/step - loss: 0.0334 - acc: 0.9893 - val_loss: 0.0142 - val_acc: 0.9958\n",
            "Epoch 13/30\n",
            "687/686 [==============================] - 7s 10ms/step - loss: 0.0303 - acc: 0.9906 - val_loss: 0.0048 - val_acc: 0.9984\n",
            "Epoch 14/30\n",
            "687/686 [==============================] - 7s 10ms/step - loss: 0.0298 - acc: 0.9908 - val_loss: 0.4804 - val_acc: 0.9073\n",
            "Epoch 15/30\n",
            "687/686 [==============================] - 7s 10ms/step - loss: 0.0272 - acc: 0.9915 - val_loss: 3.7448e-04 - val_acc: 0.9998\n",
            "Epoch 16/30\n",
            "687/686 [==============================] - 7s 11ms/step - loss: 0.0260 - acc: 0.9920 - val_loss: 0.0340 - val_acc: 0.9902\n",
            "Epoch 17/30\n",
            "687/686 [==============================] - 7s 11ms/step - loss: 0.0262 - acc: 0.9919 - val_loss: 0.0013 - val_acc: 0.9998\n",
            "Epoch 18/30\n",
            "687/686 [==============================] - 7s 11ms/step - loss: 0.0232 - acc: 0.9929 - val_loss: 4.2096e-05 - val_acc: 1.0000\n",
            "Epoch 19/30\n",
            "687/686 [==============================] - 7s 11ms/step - loss: 0.0271 - acc: 0.9920 - val_loss: 0.0116 - val_acc: 0.9964\n",
            "Epoch 20/30\n",
            "687/686 [==============================] - 7s 11ms/step - loss: 0.0189 - acc: 0.9940 - val_loss: 5.1648e-04 - val_acc: 0.9998\n",
            "Epoch 21/30\n",
            "687/686 [==============================] - 7s 10ms/step - loss: 0.0238 - acc: 0.9929 - val_loss: 7.1794e-04 - val_acc: 0.9998\n",
            "Epoch 22/30\n",
            "687/686 [==============================] - 7s 11ms/step - loss: 0.0254 - acc: 0.9933 - val_loss: 0.0088 - val_acc: 0.9960\n",
            "Epoch 23/30\n",
            "687/686 [==============================] - 7s 10ms/step - loss: 0.0232 - acc: 0.9929 - val_loss: 3.1356e-06 - val_acc: 1.0000\n",
            "Epoch 24/30\n",
            "687/686 [==============================] - 7s 10ms/step - loss: 0.0192 - acc: 0.9942 - val_loss: 8.1671e-04 - val_acc: 0.9996\n",
            "Epoch 25/30\n",
            "687/686 [==============================] - 7s 10ms/step - loss: 0.0191 - acc: 0.9950 - val_loss: 0.0087 - val_acc: 0.9967\n",
            "Epoch 26/30\n",
            "687/686 [==============================] - 7s 10ms/step - loss: 0.0174 - acc: 0.9949 - val_loss: 0.0035 - val_acc: 0.9991\n",
            "Epoch 27/30\n",
            "687/686 [==============================] - 8s 11ms/step - loss: 0.0215 - acc: 0.9939 - val_loss: 7.5623e-04 - val_acc: 0.9996\n",
            "Epoch 28/30\n",
            "687/686 [==============================] - 7s 11ms/step - loss: 0.0236 - acc: 0.9936 - val_loss: 0.0057 - val_acc: 0.9980\n",
            "Epoch 29/30\n",
            "687/686 [==============================] - 8s 11ms/step - loss: 0.0150 - acc: 0.9955 - val_loss: 4.3286e-05 - val_acc: 1.0000\n",
            "Epoch 30/30\n",
            "687/686 [==============================] - 7s 11ms/step - loss: 0.0220 - acc: 0.9936 - val_loss: 0.0044 - val_acc: 0.9987\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5bfaec3fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lngISppHdQ1h",
        "colab_type": "text"
      },
      "source": [
        "Model evaluate:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oDH6LlBdOv7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "2d07dc65-d488-42e7-e65d-b4d73b11ebf9"
      },
      "source": [
        "score, acc = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(score, acc)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7172/7172 [==============================] - 1s 83us/step\n",
            "0.25073102802432856 0.9563580591187953\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsAP49KyZuOc",
        "colab_type": "text"
      },
      "source": [
        "# **Part 3: Applying data augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqVZM_hUZxjR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "afe55643-8fae-4c0b-dbc0-3e8b244a7a0d"
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    rotation_range=20,\n",
        ")\n",
        "\n",
        "# compute quantities required for featurewise normalization\n",
        "# (std, mean, and principal components if ZCA whitening is applied)\n",
        "datagen.fit(X_train)\n",
        "\n",
        "model.load_weights('initial.h5')\n",
        "# fits the model on batches with real-time data augmentation:\n",
        "model.fit_generator(\n",
        "    datagen.flow(X_train, y_train, batch_size=32),\n",
        "    steps_per_epoch=len(X_train) / 32,\n",
        "    validation_data=datagen.flow(X_val, y_val),\n",
        "    validation_steps=len(X_val) / 32,\n",
        "    epochs=30\n",
        ")"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "687/686 [==============================] - 11s 15ms/step - loss: 1.7613 - acc: 0.4785 - val_loss: 0.7118 - val_acc: 0.7689\n",
            "Epoch 2/30\n",
            "687/686 [==============================] - 11s 15ms/step - loss: 0.7002 - acc: 0.7633 - val_loss: 0.4348 - val_acc: 0.8523\n",
            "Epoch 3/30\n",
            "687/686 [==============================] - 11s 15ms/step - loss: 0.4524 - acc: 0.8482 - val_loss: 1.2142 - val_acc: 0.6760\n",
            "Epoch 4/30\n",
            "687/686 [==============================] - 10s 15ms/step - loss: 0.3506 - acc: 0.8836 - val_loss: 0.3035 - val_acc: 0.8913\n",
            "Epoch 5/30\n",
            "687/686 [==============================] - 11s 16ms/step - loss: 0.2956 - acc: 0.8992 - val_loss: 0.1584 - val_acc: 0.9463\n",
            "Epoch 6/30\n",
            "687/686 [==============================] - 11s 15ms/step - loss: 0.2563 - acc: 0.9158 - val_loss: 1.3237 - val_acc: 0.6529\n",
            "Epoch 7/30\n",
            "687/686 [==============================] - 10s 15ms/step - loss: 0.2285 - acc: 0.9255 - val_loss: 0.0633 - val_acc: 0.9805\n",
            "Epoch 8/30\n",
            "687/686 [==============================] - 10s 15ms/step - loss: 0.2066 - acc: 0.9318 - val_loss: 0.1517 - val_acc: 0.9465\n",
            "Epoch 9/30\n",
            "687/686 [==============================] - 10s 15ms/step - loss: 0.1913 - acc: 0.9365 - val_loss: 0.0626 - val_acc: 0.9812\n",
            "Epoch 10/30\n",
            "687/686 [==============================] - 10s 15ms/step - loss: 0.1816 - acc: 0.9401 - val_loss: 0.1645 - val_acc: 0.9445\n",
            "Epoch 11/30\n",
            "687/686 [==============================] - 10s 15ms/step - loss: 0.1669 - acc: 0.9464 - val_loss: 0.1806 - val_acc: 0.9463\n",
            "Epoch 12/30\n",
            "687/686 [==============================] - 11s 16ms/step - loss: 0.1502 - acc: 0.9504 - val_loss: 0.0621 - val_acc: 0.9796\n",
            "Epoch 13/30\n",
            "687/686 [==============================] - 10s 15ms/step - loss: 0.1548 - acc: 0.9511 - val_loss: 0.0868 - val_acc: 0.9685\n",
            "Epoch 14/30\n",
            "687/686 [==============================] - 10s 15ms/step - loss: 0.1435 - acc: 0.9536 - val_loss: 0.0664 - val_acc: 0.9778\n",
            "Epoch 15/30\n",
            "687/686 [==============================] - 11s 15ms/step - loss: 0.1386 - acc: 0.9549 - val_loss: 0.1045 - val_acc: 0.9663\n",
            "Epoch 16/30\n",
            "687/686 [==============================] - 11s 16ms/step - loss: 0.1320 - acc: 0.9572 - val_loss: 0.0495 - val_acc: 0.9832\n",
            "Epoch 17/30\n",
            "687/686 [==============================] - 11s 15ms/step - loss: 0.1291 - acc: 0.9580 - val_loss: 0.0269 - val_acc: 0.9894\n",
            "Epoch 18/30\n",
            "687/686 [==============================] - 11s 16ms/step - loss: 0.1225 - acc: 0.9610 - val_loss: 0.0361 - val_acc: 0.9863\n",
            "Epoch 19/30\n",
            "687/686 [==============================] - 10s 15ms/step - loss: 0.1194 - acc: 0.9625 - val_loss: 0.0802 - val_acc: 0.9732\n",
            "Epoch 20/30\n",
            "687/686 [==============================] - 10s 15ms/step - loss: 0.1240 - acc: 0.9620 - val_loss: 0.0288 - val_acc: 0.9898\n",
            "Epoch 21/30\n",
            "687/686 [==============================] - 10s 15ms/step - loss: 0.1154 - acc: 0.9640 - val_loss: 0.0354 - val_acc: 0.9891\n",
            "Epoch 22/30\n",
            "687/686 [==============================] - 10s 15ms/step - loss: 0.1032 - acc: 0.9667 - val_loss: 0.0253 - val_acc: 0.9911\n",
            "Epoch 23/30\n",
            "687/686 [==============================] - 10s 15ms/step - loss: 0.1025 - acc: 0.9670 - val_loss: 0.0373 - val_acc: 0.9887\n",
            "Epoch 24/30\n",
            "687/686 [==============================] - 10s 15ms/step - loss: 0.1021 - acc: 0.9675 - val_loss: 0.0216 - val_acc: 0.9927\n",
            "Epoch 25/30\n",
            "687/686 [==============================] - 10s 15ms/step - loss: 0.1024 - acc: 0.9678 - val_loss: 0.0089 - val_acc: 0.9967\n",
            "Epoch 26/30\n",
            "687/686 [==============================] - 10s 15ms/step - loss: 0.1063 - acc: 0.9684 - val_loss: 0.0169 - val_acc: 0.9942\n",
            "Epoch 27/30\n",
            "687/686 [==============================] - 11s 15ms/step - loss: 0.1019 - acc: 0.9675 - val_loss: 0.0547 - val_acc: 0.9814\n",
            "Epoch 28/30\n",
            "687/686 [==============================] - 11s 15ms/step - loss: 0.0963 - acc: 0.9694 - val_loss: 0.0141 - val_acc: 0.9956\n",
            "Epoch 29/30\n",
            "687/686 [==============================] - 10s 15ms/step - loss: 0.0915 - acc: 0.9725 - val_loss: 0.0367 - val_acc: 0.9893\n",
            "Epoch 30/30\n",
            "687/686 [==============================] - 11s 15ms/step - loss: 0.0960 - acc: 0.9699 - val_loss: 0.0638 - val_acc: 0.9778\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5bfaecb668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62m3cyt9dke2",
        "colab_type": "text"
      },
      "source": [
        "Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzpVv_6adnwM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "8b98f85c-06c5-4e8d-c57e-83287802b92f"
      },
      "source": [
        "score, acc = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(score, acc)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7172/7172 [==============================] - 1s 88us/step\n",
            "0.1272765828419629 0.9553820412716119\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCiwhOILhYoD",
        "colab_type": "text"
      },
      "source": [
        "# **Part 4: Using transfer learning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqpN9RyyhTIA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "outputId": "ecf0274f-b7d1-404d-8419-078150676d4e"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.applications.vgg16 import VGG16\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "def x_to_vgg_input(X):\n",
        "    x = [i for i in X]\n",
        "    #x = [cv2.cvtColor(cv2.resize(i, (32,32)), cv2.COLOR_GRAY2BGR) for i in X]\n",
        "    #x = np.concatenate([arr[np.newaxis] for arr in x]).astype('float32')\n",
        "    #x = [np.repeat(i[..., np.newaxis], 3, -1) for i in x]\n",
        "    #x = np.repeat(x[..., np.newaxis], 3, -1)\n",
        "    print(len(x[0]))\n",
        "    return x\n",
        "\n",
        "# load model\n",
        "vgg = VGG16(include_top=False, input_shape=(32, 32, 3))\n",
        "# mark loaded layers as not trainable\n",
        "for layer in vgg.layers:\n",
        "\tlayer.trainable = False\n",
        "\n",
        "# define a new output layer to connect with the last fc layer in vgg\n",
        "x = Flatten()(vgg.layers[-1].output)\n",
        "class1 = Dense(512, activation='relu', kernel_initializer='he_uniform')(x)\n",
        "bn = BatchNormalization()(class1)\n",
        "do = Dropout(0.5)(bn)\n",
        "output_layer = Dense(LABELS, activation='softmax', name='predictions')(do)\n",
        "\n",
        "# combine the original VGG model with the new output layer\n",
        "vgg = Model(inputs=vgg.input, outputs=output_layer)\n",
        "\n",
        "vgg.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])\n",
        "x_to_vgg_input(X_train)\n",
        "vgg.fit(\n",
        "    x=x_to_vgg_input(X_train),\n",
        "    y=y_train,\n",
        "    batch_size=32,\n",
        "    steps_per_epoch=len(X_train) / 32,\n",
        "    epochs=30\n",
        ")"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28\n",
            "28\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-93-12b0a7825bf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                 str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             raise ValueError(\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 21964 arrays: [array([[[0.38039216],\n        [0.25490196],\n        [0.50196078],\n        [0.17254902],\n        [0.06666667],\n        [0.2627451 ],\n        [0.25098039],\n        [0.25882353],\n        [0.27058824],\n ..."
          ]
        }
      ]
    }
  ]
}