{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "lab.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "WZfImSn8R0d0",
        "colab_type": "text"
      },
      "source": [
        "<b>Google Colab</b> <a href=\"https://colab.research.google.com/github/kirillzyusko/deeplearning/blob/master/6/lab.ipynb\">link</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jALamvtBs_59",
        "colab_type": "text"
      },
      "source": [
        "Authorize google + kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBIxqfvSR0d2",
        "colab_type": "code",
        "outputId": "a04e97c4-d96d-4139-9a7f-822026ef5f47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from googleapiclient.discovery import build\n",
        "import io, os\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "results = drive_service.files().list(\n",
        "        q=\"name = 'kaggle.json'\", fields=\"files(id)\").execute()\n",
        "kaggle_api_key = results.get('files', [])\n",
        "filename = \"/content/.kaggle/kaggle.json\"\n",
        "os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "request = drive_service.files().get_media(fileId=kaggle_api_key[0]['id'])\n",
        "fh = io.FileIO(filename, 'wb')\n",
        "downloader = MediaIoBaseDownload(fh, request)\n",
        "done = False\n",
        "while done is False:\n",
        "    status, done = downloader.next_chunk()\n",
        "    print(\"Download %d%%.\" % int(status.progress() * 100))\n",
        "os.chmod(filename, 600)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Download 100%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRXF9HEfw-Lq",
        "colab_type": "text"
      },
      "source": [
        "Be sure, that we authorized and have an access to kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHH44E0AR0d5",
        "colab_type": "code",
        "outputId": "bb550c2c-5a04-483c-a4f2-4231383f1fc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%ls /content/.kaggle/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;32mkaggle.json\u001b[0m*\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scuK4S5oxDjd",
        "colab_type": "text"
      },
      "source": [
        "# **Part 1: Download dataset, extract, split, check data distribution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGGxcFMNxLuf",
        "colab_type": "code",
        "outputId": "bc5c2101-db8d-4b0b-ebdb-d8703877a594",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download datamunge/sign-language-mnist -p /content/kaggle/signlanguage"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading sign-language-mnist.zip to /content/kaggle/signlanguage\n",
            " 53% 33.0M/62.6M [00:01<00:01, 26.5MB/s]\n",
            "100% 62.6M/62.6M [00:01<00:00, 44.6MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrCRUpSRxjGY",
        "colab_type": "text"
      },
      "source": [
        "Extract .zip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vqOKF6azu8E",
        "colab_type": "code",
        "outputId": "82f31db9-1ea8-4b35-a715-57c3e8f82b18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "!unzip kaggle/signlanguage/sign-language-mnist.zip -d data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  kaggle/signlanguage/sign-language-mnist.zip\n",
            "  inflating: data/amer_sign2.png     \n",
            "  inflating: data/amer_sign3.png     \n",
            "  inflating: data/american_sign_language.PNG  \n",
            "  inflating: data/sign_mnist_test.csv  \n",
            "  inflating: data/sign_mnist_test/sign_mnist_test.csv  \n",
            "  inflating: data/sign_mnist_train.csv  \n",
            "  inflating: data/sign_mnist_train/sign_mnist_train.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXejvzHg0bs8",
        "colab_type": "code",
        "outputId": "9528845d-4eab-4a21-e3ee-0ffb6d814407",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json  \u001b[0m\u001b[01;34mdata\u001b[0m/  \u001b[01;34mkaggle\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMvk2CF40ieg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "TRAIN_PATH = './data/sign_mnist_train.csv'\n",
        "TEST_PATH = './data/sign_mnist_test.csv'\n",
        "\n",
        "IMAGE_WIDTH=28\n",
        "IMAGE_HEIGHT=28\n",
        "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
        "IMAGE_CHANNELS=1\n",
        "\n",
        "train = pd.read_csv(TRAIN_PATH)\n",
        "test = pd.read_csv(TEST_PATH)\n",
        "\n",
        "# train, val = train_test_split(train, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "def split_dataset_to_x_y(df, is_numpy=True):\n",
        "    y = pd.concat([df['label'], pd.get_dummies(df['label'], prefix='label')], axis=1)\n",
        "    df.drop(['label'], axis=1, inplace=True)\n",
        "    y.drop(['label'], axis=1, inplace=True)\n",
        "    X = (df / 255).values.reshape((df.shape[0], IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS))  # data scaling & reshaping\n",
        "\n",
        "    return X, y.to_numpy() if is_numpy else y\n",
        "\n",
        "\n",
        "X, Y = split_dataset_to_x_y(train)\n",
        "X_test, Y_test = split_dataset_to_x_y(test, is_numpy=False)\n",
        "\n",
        "LABELS = 24"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WO6wDC9XMjNP",
        "colab_type": "text"
      },
      "source": [
        "Check data distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDZwfbvhMz8o",
        "colab_type": "code",
        "outputId": "d611de25-ee07-4757-f3a4-d90617d78e7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "y_test.value_counts().plot.bar()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5cb63ed550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD7CAYAAACRxdTpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUoUMd0mq0P8DtNN9iUuh27UAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsUNBunlM9Bk",
        "colab_type": "code",
        "outputId": "10183760-1ff5-4f79-d7d3-cf8d06d3e4f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "y_val.value_counts().plot.bar()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5cb4ce1eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD7CAYAAACRxdTpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlljl4QIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5h6wx_p0NBRW",
        "colab_type": "code",
        "outputId": "eb390097-b0bd-432f-fea5-30f6b56f855b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "y_train.value_counts().plot.bar()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5cb4c5d940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD7CAYAAACG50QgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jx9JdwO0NLOY",
        "colab_type": "text"
      },
      "source": [
        "# **Part 2: DNN model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCj7TIb6NO5R",
        "colab_type": "code",
        "outputId": "fbd9d8a1-6a36-492a-eb6e-aa989cfe808a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(LABELS, activation='softmax')) # 2 classes: dog and cat\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.save_weights('initial.h5')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 26, 26, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 11, 11, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 3, 3, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 3, 3, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               66048     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 24)                12312     \n",
            "=================================================================\n",
            "Total params: 173,976\n",
            "Trainable params: 172,504\n",
            "Non-trainable params: 1,472\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifky2VHCOYJ6",
        "colab_type": "text"
      },
      "source": [
        "Train without data augmentation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWFivKKXOb8H",
        "colab_type": "code",
        "outputId": "843cfd24-c104-4852-876c-32a722d8da4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "n_folds = 10\n",
        "skf = KFold(n_folds, shuffle=True).split(X)\n",
        "\n",
        "datagen = ImageDataGenerator()\n",
        "datagen.fit(X)\n",
        "# compute quantities required for featurewise normalization\n",
        "# (std, mean, and principal components if ZCA whitening is applied)\n",
        "\n",
        "model.load_weights('initial.h5')\n",
        "\n",
        "for train_index, test_index in skf:\n",
        "    x_train,x_test=X[train_index],X[test_index]\n",
        "    y_train,y_test=Y[train_index],Y[test_index]\n",
        "    model.fit_generator(\n",
        "      datagen.flow(x_train, y_train, batch_size=32),\n",
        "      steps_per_epoch=len(x_train) / 32,\n",
        "      validation_data=datagen.flow(x_test, y_test),\n",
        "      validation_steps=len(x_test) / 32,\n",
        "      epochs=3\n",
        "    )"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "773/772 [==============================] - 7s 9ms/step - loss: 1.2126 - acc: 0.6373 - val_loss: 0.1387 - val_acc: 0.9599\n",
            "Epoch 2/3\n",
            "773/772 [==============================] - 7s 9ms/step - loss: 0.2359 - acc: 0.9206 - val_loss: 0.0832 - val_acc: 0.9720\n",
            "Epoch 3/3\n",
            "773/772 [==============================] - 7s 9ms/step - loss: 0.1167 - acc: 0.9611 - val_loss: 0.1063 - val_acc: 0.9654\n",
            "Epoch 1/3\n",
            "773/772 [==============================] - 7s 9ms/step - loss: 0.0874 - acc: 0.9722 - val_loss: 0.0085 - val_acc: 0.9964\n",
            "Epoch 2/3\n",
            "773/772 [==============================] - 7s 9ms/step - loss: 0.0606 - acc: 0.9795 - val_loss: 0.0477 - val_acc: 0.9825\n",
            "Epoch 3/3\n",
            "773/772 [==============================] - 7s 9ms/step - loss: 0.0590 - acc: 0.9814 - val_loss: 0.0521 - val_acc: 0.9843\n",
            "Epoch 1/3\n",
            "773/772 [==============================] - 7s 9ms/step - loss: 0.0460 - acc: 0.9857 - val_loss: 0.0062 - val_acc: 0.9971\n",
            "Epoch 2/3\n",
            "773/772 [==============================] - 7s 9ms/step - loss: 0.0429 - acc: 0.9854 - val_loss: 0.2548 - val_acc: 0.9297\n",
            "Epoch 3/3\n",
            "773/772 [==============================] - 7s 9ms/step - loss: 0.0405 - acc: 0.9873 - val_loss: 7.3353e-04 - val_acc: 1.0000\n",
            "Epoch 1/3\n",
            "773/772 [==============================] - 7s 9ms/step - loss: 0.0310 - acc: 0.9901 - val_loss: 8.6260e-04 - val_acc: 0.9996\n",
            "Epoch 2/3\n",
            "773/772 [==============================] - 7s 9ms/step - loss: 0.0327 - acc: 0.9902 - val_loss: 0.0521 - val_acc: 0.9865\n",
            "Epoch 3/3\n",
            "773/772 [==============================] - 7s 9ms/step - loss: 0.0298 - acc: 0.9912 - val_loss: 5.3144e-04 - val_acc: 0.9996\n",
            "Epoch 1/3\n",
            "773/772 [==============================] - 7s 9ms/step - loss: 0.0293 - acc: 0.9910 - val_loss: 0.0069 - val_acc: 0.9982\n",
            "Epoch 2/3\n",
            "773/772 [==============================] - 7s 9ms/step - loss: 0.0319 - acc: 0.9913 - val_loss: 0.0049 - val_acc: 0.9978\n",
            "Epoch 3/3\n",
            "773/772 [==============================] - 7s 9ms/step - loss: 0.0236 - acc: 0.9924 - val_loss: 6.3637e-06 - val_acc: 1.0000\n",
            "Epoch 1/3\n",
            "773/772 [==============================] - 7s 9ms/step - loss: 0.0260 - acc: 0.9919 - val_loss: 0.0139 - val_acc: 0.9945\n",
            "Epoch 2/3\n",
            "773/772 [==============================] - 7s 9ms/step - loss: 0.0197 - acc: 0.9945 - val_loss: 1.1208e-04 - val_acc: 1.0000\n",
            "Epoch 3/3\n",
            "773/772 [==============================] - 7s 9ms/step - loss: 0.0225 - acc: 0.9929 - val_loss: 0.0067 - val_acc: 0.9982\n",
            "Epoch 1/3\n",
            "773/772 [==============================] - 7s 9ms/step - loss: 0.0194 - acc: 0.9937 - val_loss: 0.0871 - val_acc: 0.9734\n",
            "Epoch 2/3\n",
            "773/772 [==============================] - 7s 9ms/step - loss: 0.0205 - acc: 0.9931 - val_loss: 8.4198e-07 - val_acc: 1.0000\n",
            "Epoch 3/3\n",
            "773/772 [==============================] - 7s 9ms/step - loss: 0.0167 - acc: 0.9944 - val_loss: 1.2897e-05 - val_acc: 1.0000\n",
            "Epoch 1/3\n",
            "773/772 [==============================] - 7s 9ms/step - loss: 0.0274 - acc: 0.9928 - val_loss: 0.0171 - val_acc: 0.9945\n",
            "Epoch 2/3\n",
            "773/772 [==============================] - 7s 9ms/step - loss: 0.0239 - acc: 0.9928 - val_loss: 0.0125 - val_acc: 0.9971\n",
            "Epoch 3/3\n",
            "773/772 [==============================] - 7s 9ms/step - loss: 0.0218 - acc: 0.9939 - val_loss: 0.0206 - val_acc: 0.9927\n",
            "Epoch 1/3\n",
            "773/772 [==============================] - 7s 9ms/step - loss: 0.0174 - acc: 0.9945 - val_loss: 8.0928e-05 - val_acc: 1.0000\n",
            "Epoch 2/3\n",
            "773/772 [==============================] - 7s 9ms/step - loss: 0.0208 - acc: 0.9944 - val_loss: 1.3877e-05 - val_acc: 1.0000\n",
            "Epoch 3/3\n",
            "773/772 [==============================] - 7s 9ms/step - loss: 0.0232 - acc: 0.9934 - val_loss: 6.2000e-05 - val_acc: 1.0000\n",
            "Epoch 1/3\n",
            "773/772 [==============================] - 7s 9ms/step - loss: 0.0174 - acc: 0.9940 - val_loss: 4.5417e-06 - val_acc: 1.0000\n",
            "Epoch 2/3\n",
            "773/772 [==============================] - 7s 9ms/step - loss: 0.0176 - acc: 0.9943 - val_loss: 8.1917e-05 - val_acc: 1.0000\n",
            "Epoch 3/3\n",
            "773/772 [==============================] - 7s 9ms/step - loss: 0.0192 - acc: 0.9945 - val_loss: 4.2321e-07 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lngISppHdQ1h",
        "colab_type": "text"
      },
      "source": [
        "Model evaluate:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oDH6LlBdOv7",
        "colab_type": "code",
        "outputId": "5128bb84-d5d1-47c3-edd7-79c0fbb78699",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "score, acc = model.evaluate(X_test, Y_test, verbose=1)\n",
        "print(score, acc)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7172/7172 [==============================] - 1s 76us/step\n",
            "0.2936273631751099 0.9562186279977691\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsAP49KyZuOc",
        "colab_type": "text"
      },
      "source": [
        "# **Part 3: Applying data augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqVZM_hUZxjR",
        "colab_type": "code",
        "outputId": "1f971464-422d-4744-9d6b-0f6bbd26c0c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    rotation_range=20,\n",
        ")\n",
        "\n",
        "# compute quantities required for featurewise normalization\n",
        "# (std, mean, and principal components if ZCA whitening is applied)\n",
        "datagen.fit(X)\n",
        "\n",
        "skf = KFold(n_folds, shuffle=True).split(X)\n",
        "\n",
        "model.load_weights('initial.h5')\n",
        "# fits the model on batches with real-time data augmentation:\n",
        "for train_index, test_index in skf:\n",
        "    x_train,x_test=X[train_index],X[test_index]\n",
        "    y_train,y_test=Y[train_index],Y[test_index]\n",
        "    model.fit_generator(\n",
        "      datagen.flow(x_train, y_train, batch_size=32),\n",
        "      steps_per_epoch=len(x_train) / 32,\n",
        "      validation_data=datagen.flow(x_test, y_test),\n",
        "      validation_steps=len(x_test) / 32,\n",
        "      epochs=3\n",
        "    )"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "773/772 [==============================] - 10s 14ms/step - loss: 1.6367 - acc: 0.5087 - val_loss: 0.5759 - val_acc: 0.8044\n",
            "Epoch 2/3\n",
            "773/772 [==============================] - 11s 14ms/step - loss: 0.6613 - acc: 0.7774 - val_loss: 0.3136 - val_acc: 0.8933\n",
            "Epoch 3/3\n",
            "773/772 [==============================] - 10s 14ms/step - loss: 0.4256 - acc: 0.8552 - val_loss: 0.1953 - val_acc: 0.9348\n",
            "Epoch 1/3\n",
            "773/772 [==============================] - 11s 14ms/step - loss: 0.3292 - acc: 0.8900 - val_loss: 0.0796 - val_acc: 0.9727\n",
            "Epoch 2/3\n",
            "773/772 [==============================] - 11s 14ms/step - loss: 0.2912 - acc: 0.9042 - val_loss: 0.0758 - val_acc: 0.9778\n",
            "Epoch 3/3\n",
            "773/772 [==============================] - 11s 14ms/step - loss: 0.2499 - acc: 0.9172 - val_loss: 0.0642 - val_acc: 0.9782\n",
            "Epoch 1/3\n",
            "773/772 [==============================] - 11s 14ms/step - loss: 0.2213 - acc: 0.9286 - val_loss: 0.2211 - val_acc: 0.9334\n",
            "Epoch 2/3\n",
            "773/772 [==============================] - 11s 14ms/step - loss: 0.1907 - acc: 0.9372 - val_loss: 0.1480 - val_acc: 0.9472\n",
            "Epoch 3/3\n",
            "773/772 [==============================] - 11s 14ms/step - loss: 0.1837 - acc: 0.9406 - val_loss: 0.1393 - val_acc: 0.9527\n",
            "Epoch 1/3\n",
            "773/772 [==============================] - 11s 14ms/step - loss: 0.1685 - acc: 0.9447 - val_loss: 0.1655 - val_acc: 0.9432\n",
            "Epoch 2/3\n",
            "773/772 [==============================] - 11s 14ms/step - loss: 0.1551 - acc: 0.9493 - val_loss: 0.4950 - val_acc: 0.8387\n",
            "Epoch 3/3\n",
            "773/772 [==============================] - 11s 14ms/step - loss: 0.1576 - acc: 0.9490 - val_loss: 0.0168 - val_acc: 0.9956\n",
            "Epoch 1/3\n",
            "773/772 [==============================] - 11s 14ms/step - loss: 0.1453 - acc: 0.9526 - val_loss: 0.0367 - val_acc: 0.9862\n",
            "Epoch 2/3\n",
            "773/772 [==============================] - 11s 14ms/step - loss: 0.1420 - acc: 0.9554 - val_loss: 0.1533 - val_acc: 0.9501\n",
            "Epoch 3/3\n",
            "773/772 [==============================] - 10s 13ms/step - loss: 0.1375 - acc: 0.9561 - val_loss: 0.0806 - val_acc: 0.9767\n",
            "Epoch 1/3\n",
            "773/772 [==============================] - 10s 13ms/step - loss: 0.1295 - acc: 0.9575 - val_loss: 0.0455 - val_acc: 0.9825\n",
            "Epoch 2/3\n",
            "773/772 [==============================] - 11s 14ms/step - loss: 0.1242 - acc: 0.9594 - val_loss: 0.0418 - val_acc: 0.9854\n",
            "Epoch 3/3\n",
            "773/772 [==============================] - 10s 13ms/step - loss: 0.1231 - acc: 0.9615 - val_loss: 0.1175 - val_acc: 0.9617\n",
            "Epoch 1/3\n",
            "773/772 [==============================] - 11s 14ms/step - loss: 0.1185 - acc: 0.9620 - val_loss: 0.0470 - val_acc: 0.9851\n",
            "Epoch 2/3\n",
            "773/772 [==============================] - 11s 14ms/step - loss: 0.1141 - acc: 0.9626 - val_loss: 0.0068 - val_acc: 0.9982\n",
            "Epoch 3/3\n",
            "773/772 [==============================] - 10s 13ms/step - loss: 0.1101 - acc: 0.9650 - val_loss: 0.0327 - val_acc: 0.9891\n",
            "Epoch 1/3\n",
            "773/772 [==============================] - 11s 14ms/step - loss: 0.1058 - acc: 0.9669 - val_loss: 0.1610 - val_acc: 0.9464\n",
            "Epoch 2/3\n",
            "773/772 [==============================] - 11s 14ms/step - loss: 0.1043 - acc: 0.9677 - val_loss: 0.0629 - val_acc: 0.9778\n",
            "Epoch 3/3\n",
            "773/772 [==============================] - 10s 13ms/step - loss: 0.1042 - acc: 0.9671 - val_loss: 0.0152 - val_acc: 0.9956\n",
            "Epoch 1/3\n",
            "773/772 [==============================] - 11s 14ms/step - loss: 0.1035 - acc: 0.9685 - val_loss: 0.1734 - val_acc: 0.9417\n",
            "Epoch 2/3\n",
            "773/772 [==============================] - 11s 14ms/step - loss: 0.1037 - acc: 0.9686 - val_loss: 0.0336 - val_acc: 0.9891\n",
            "Epoch 3/3\n",
            "773/772 [==============================] - 11s 14ms/step - loss: 0.0986 - acc: 0.9685 - val_loss: 0.0499 - val_acc: 0.9829\n",
            "Epoch 1/3\n",
            "773/772 [==============================] - 11s 14ms/step - loss: 0.1016 - acc: 0.9696 - val_loss: 0.0676 - val_acc: 0.9734\n",
            "Epoch 2/3\n",
            "773/772 [==============================] - 10s 13ms/step - loss: 0.0930 - acc: 0.9708 - val_loss: 0.0296 - val_acc: 0.9902\n",
            "Epoch 3/3\n",
            "773/772 [==============================] - 10s 13ms/step - loss: 0.0950 - acc: 0.9706 - val_loss: 0.0097 - val_acc: 0.9971\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62m3cyt9dke2",
        "colab_type": "text"
      },
      "source": [
        "Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzpVv_6adnwM",
        "colab_type": "code",
        "outputId": "355e0c1b-50f8-4fcb-8540-83440513b04d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "score, acc = model.evaluate(X_test, Y_test, verbose=1)\n",
        "print(score, acc)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7172/7172 [==============================] - 1s 80us/step\n",
            "0.12932936984590399 0.9556609035136643\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCiwhOILhYoD",
        "colab_type": "text"
      },
      "source": [
        "# **Part 4: Using transfer learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0K7UsUBI-Qv",
        "colab_type": "text"
      },
      "source": [
        "Data transforamtion for applying VGG transfer learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5PXgXl1I3OZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "def x_to_vgg_input(X):\n",
        "    x = np.reshape(X, (X.shape[0], 28, 28))\n",
        "    x = np.asarray([cv2.resize(i, (32,32)) for i in x], dtype=np.float32)\n",
        "    x = np.repeat(x[..., np.newaxis], 3, -1)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_KM6AcrJLs7",
        "colab_type": "text"
      },
      "source": [
        "Defining NN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tv1wWWXsI5DV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "f8ae2822-84f5-4fd7-dab5-21b3e0a3fe0b"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
        "\n",
        "# load model\n",
        "vgg = VGG16(include_top=False, input_shape=(32, 32, 3))\n",
        "# mark loaded layers as not trainable\n",
        "for layer in vgg.layers:\n",
        "\tlayer.trainable = False\n",
        "\n",
        "# define a new output layer to connect with the last fc layer in vgg\n",
        "x = Flatten()(vgg.layers[-1].output)\n",
        "class1 = Dense(512, activation='relu', kernel_initializer='he_uniform')(x)\n",
        "bn = BatchNormalization()(class1)\n",
        "do = Dropout(0.5)(bn)\n",
        "output_layer = Dense(LABELS, activation='softmax', name='predictions')(do)\n",
        "\n",
        "# combine the original VGG model with the new output layer\n",
        "vgg = Model(inputs=vgg.input, outputs=output_layer)\n",
        "\n",
        "vgg.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBZUIMUWI5Oe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    rotation_range=20,\n",
        ")\n",
        "\n",
        "# compute quantities required for featurewise normalization\n",
        "# (std, mean, and principal components if ZCA whitening is applied)\n",
        "datagen.fit(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXO33rGSJ34Z",
        "colab_type": "text"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAJVy3ArI5V_",
        "colab_type": "code",
        "outputId": "e19b1dc5-40b0-4ea9-fa2a-cc1379dd248a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# fits the model on batches with real-time data augmentation:\n",
        "skf = KFold(n_folds, shuffle=True).split(X)\n",
        "\n",
        "# fits the model on batches with real-time data augmentation:\n",
        "for train_index, test_index in skf:\n",
        "    x_train,x_test=X[train_index],X[test_index]\n",
        "    y_train,y_test=Y[train_index],Y[test_index]\n",
        "    vgg.fit_generator(\n",
        "      datagen.flow(x_to_vgg_input(x_train), y_train, batch_size=32),\n",
        "      steps_per_epoch=len(x_train) / 32,\n",
        "      validation_data=datagen.flow(x_to_vgg_input(x_test), y_test),\n",
        "      validation_steps=len(x_test) / 32,\n",
        "      epochs=3\n",
        "    )"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "773/772 [==============================] - 18s 23ms/step - loss: 0.9605 - acc: 0.6881 - val_loss: 0.5249 - val_acc: 0.8285\n",
            "Epoch 2/3\n",
            "773/772 [==============================] - 17s 22ms/step - loss: 0.5059 - acc: 0.8283 - val_loss: 0.4967 - val_acc: 0.8161\n",
            "Epoch 3/3\n",
            "773/772 [==============================] - 17s 22ms/step - loss: 0.4127 - acc: 0.8594 - val_loss: 0.3566 - val_acc: 0.8762\n",
            "Epoch 1/3\n",
            "773/772 [==============================] - 17s 21ms/step - loss: 0.3751 - acc: 0.8715 - val_loss: 0.3257 - val_acc: 0.8980\n",
            "Epoch 2/3\n",
            "773/772 [==============================] - 17s 21ms/step - loss: 0.3522 - acc: 0.8763 - val_loss: 0.3365 - val_acc: 0.8751\n",
            "Epoch 3/3\n",
            "773/772 [==============================] - 16s 21ms/step - loss: 0.3455 - acc: 0.8834 - val_loss: 0.2590 - val_acc: 0.9119\n",
            "Epoch 1/3\n",
            "773/772 [==============================] - 17s 21ms/step - loss: 0.3267 - acc: 0.8883 - val_loss: 0.3198 - val_acc: 0.8827\n",
            "Epoch 2/3\n",
            "773/772 [==============================] - 17s 21ms/step - loss: 0.3178 - acc: 0.8917 - val_loss: 0.2034 - val_acc: 0.9294\n",
            "Epoch 3/3\n",
            "773/772 [==============================] - 16s 21ms/step - loss: 0.3098 - acc: 0.8949 - val_loss: 0.2203 - val_acc: 0.9268\n",
            "Epoch 1/3\n",
            "773/772 [==============================] - 16s 21ms/step - loss: 0.2980 - acc: 0.8975 - val_loss: 0.2068 - val_acc: 0.9279\n",
            "Epoch 2/3\n",
            "773/772 [==============================] - 17s 22ms/step - loss: 0.2951 - acc: 0.8992 - val_loss: 0.2038 - val_acc: 0.9243\n",
            "Epoch 3/3\n",
            "773/772 [==============================] - 16s 21ms/step - loss: 0.3060 - acc: 0.8942 - val_loss: 0.1793 - val_acc: 0.9410\n",
            "Epoch 1/3\n",
            "773/772 [==============================] - 17s 21ms/step - loss: 0.2916 - acc: 0.9014 - val_loss: 0.1808 - val_acc: 0.9363\n",
            "Epoch 2/3\n",
            "773/772 [==============================] - 16s 21ms/step - loss: 0.2906 - acc: 0.9016 - val_loss: 0.2068 - val_acc: 0.9352\n",
            "Epoch 3/3\n",
            "773/772 [==============================] - 16s 21ms/step - loss: 0.3006 - acc: 0.8992 - val_loss: 0.1803 - val_acc: 0.9326\n",
            "Epoch 1/3\n",
            "773/772 [==============================] - 17s 21ms/step - loss: 0.2900 - acc: 0.9015 - val_loss: 0.1667 - val_acc: 0.9454\n",
            "Epoch 2/3\n",
            "773/772 [==============================] - 16s 21ms/step - loss: 0.2886 - acc: 0.9021 - val_loss: 0.2127 - val_acc: 0.9206\n",
            "Epoch 3/3\n",
            "773/772 [==============================] - 16s 21ms/step - loss: 0.2877 - acc: 0.9047 - val_loss: 0.1707 - val_acc: 0.9450\n",
            "Epoch 1/3\n",
            "773/772 [==============================] - 16s 21ms/step - loss: 0.2871 - acc: 0.9055 - val_loss: 0.1910 - val_acc: 0.9373\n",
            "Epoch 2/3\n",
            "773/772 [==============================] - 16s 21ms/step - loss: 0.2800 - acc: 0.9030 - val_loss: 0.1804 - val_acc: 0.9373\n",
            "Epoch 3/3\n",
            "773/772 [==============================] - 16s 21ms/step - loss: 0.2759 - acc: 0.9060 - val_loss: 0.1467 - val_acc: 0.9530\n",
            "Epoch 1/3\n",
            "773/772 [==============================] - 17s 21ms/step - loss: 0.2752 - acc: 0.9051 - val_loss: 0.2445 - val_acc: 0.9118\n",
            "Epoch 2/3\n",
            "773/772 [==============================] - 16s 21ms/step - loss: 0.2706 - acc: 0.9082 - val_loss: 0.1804 - val_acc: 0.9362\n",
            "Epoch 3/3\n",
            "773/772 [==============================] - 16s 21ms/step - loss: 0.2816 - acc: 0.9023 - val_loss: 0.1622 - val_acc: 0.9450\n",
            "Epoch 1/3\n",
            "773/772 [==============================] - 16s 21ms/step - loss: 0.2763 - acc: 0.9063 - val_loss: 0.1415 - val_acc: 0.9526\n",
            "Epoch 2/3\n",
            "773/772 [==============================] - 16s 21ms/step - loss: 0.2749 - acc: 0.9063 - val_loss: 0.1818 - val_acc: 0.9355\n",
            "Epoch 3/3\n",
            "773/772 [==============================] - 17s 22ms/step - loss: 0.2768 - acc: 0.9049 - val_loss: 0.1754 - val_acc: 0.9381\n",
            "Epoch 1/3\n",
            "773/772 [==============================] - 16s 21ms/step - loss: 0.2753 - acc: 0.9074 - val_loss: 0.1638 - val_acc: 0.9483\n",
            "Epoch 2/3\n",
            "773/772 [==============================] - 16s 21ms/step - loss: 0.2742 - acc: 0.9072 - val_loss: 0.1422 - val_acc: 0.9526\n",
            "Epoch 3/3\n",
            "773/772 [==============================] - 16s 21ms/step - loss: 0.2703 - acc: 0.9064 - val_loss: 0.1423 - val_acc: 0.9497\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTyeQItxHN13",
        "colab_type": "text"
      },
      "source": [
        "Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xj-Za6gGHX55",
        "colab_type": "code",
        "outputId": "75be0831-7e70-4a39-c636-7519073e532d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "score, acc = vgg.evaluate(x_to_vgg_input(X_test), Y_test, verbose=1)\n",
        "print(score, acc)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7172/7172 [==============================] - 3s 366us/step\n",
            "0.22242178853520186 0.9277746793084216\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}